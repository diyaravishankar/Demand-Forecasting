{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Load Data Cleaning Explanation\n",
    "\n",
    "This notebook descrbes the process used to construct and clean the dataset.\n",
    "\n",
    "Data was aquired from entsoe Transparency Platform at the following [link](https://transparency.entsoe.eu/load-domain/r2/totalLoadR2/show?name=&defaultValue=false&viewType=TABLE&areaType=BZN&atch=false&dateTime.dateTime=09.08.2015+00:00|CET|DAY&biddingZone.values=CTY|10YES-REE------0!BZN|10YES-REE------0&dateTime.timezone=CET_CEST&dateTime.timezone_input=CET+(UTC+1)+/+CEST+(UTC+2)#) (2015 data). Data is downloadable on an annual basis. this workbook constructs an example dataset using the years 2016-2018. The same functions may be used to construct any number of years available from this source.\n",
    "\n",
    "Processes completed in the following functions:\n",
    "1. format_data\n",
    "    - renames the columns\n",
    "    - shortens the text identifier for times\n",
    "    - converts to a Datetime index\n",
    "2. combine_annual_data\n",
    "    - joins a dictionary if dataframes\n",
    "3. interpolate_nans\n",
    "    - fills the missing values using a linear interpolation method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6776\r\n",
      "-rw-r--r--@ 1 ns  staff  473123 18 Aug 20:03 Total Load - Day Ahead _ Actual_2015.csv\r\n",
      "-rw-r--r--@ 1 ns  staff  474463 18 Aug 20:03 Total Load - Day Ahead _ Actual_2016.csv\r\n",
      "-rw-r--r--@ 1 ns  staff  473173 18 Aug 20:03 Total Load - Day Ahead _ Actual_2017.csv\r\n",
      "-rw-r--r--@ 1 ns  staff  473173 18 Aug 20:00 Total Load - Day Ahead _ Actual_2018.csv\r\n",
      "-rw-r--r--@ 1 ns  staff  447309 18 Aug 20:00 Total Load - Day Ahead _ Actual_2019.csv\r\n",
      "-rw-r--r--  1 ns  staff  946953 20 Aug 19:42 load_forecast_2016_2018.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./data/raw_data_ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/raw_data_ES/'\n",
    "files = ['Total Load - Day Ahead _ Actual_2015.csv',\n",
    "            'Total Load - Day Ahead _ Actual_2016.csv',\n",
    "            'Total Load - Day Ahead _ Actual_2017.csv',\n",
    "            'Total Load - Day Ahead _ Actual_2018.csv',\n",
    "            'Total Load - Day Ahead _ Actual_2019.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in list of the datasets\n",
    "data_sets = [pd.read_csv(path+file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (CET)</th>\n",
       "      <th>Day-ahead Total Load Forecast [MW] - BZN|ES</th>\n",
       "      <th>Actual Total Load [MW] - BZN|ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2015 00:00 - 01.01.2015 01:00</td>\n",
       "      <td>26118.0</td>\n",
       "      <td>25385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2015 01:00 - 01.01.2015 02:00</td>\n",
       "      <td>24934.0</td>\n",
       "      <td>24382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2015 02:00 - 01.01.2015 03:00</td>\n",
       "      <td>23515.0</td>\n",
       "      <td>22734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2015 03:00 - 01.01.2015 04:00</td>\n",
       "      <td>22642.0</td>\n",
       "      <td>21286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2015 04:00 - 01.01.2015 05:00</td>\n",
       "      <td>21785.0</td>\n",
       "      <td>20264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01.01.2015 05:00 - 01.01.2015 06:00</td>\n",
       "      <td>21441.0</td>\n",
       "      <td>19905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01.01.2015 06:00 - 01.01.2015 07:00</td>\n",
       "      <td>21285.0</td>\n",
       "      <td>20010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01.01.2015 07:00 - 01.01.2015 08:00</td>\n",
       "      <td>21545.0</td>\n",
       "      <td>20377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01.01.2015 08:00 - 01.01.2015 09:00</td>\n",
       "      <td>21443.0</td>\n",
       "      <td>20094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01.01.2015 09:00 - 01.01.2015 10:00</td>\n",
       "      <td>21560.0</td>\n",
       "      <td>20637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01.01.2015 10:00 - 01.01.2015 11:00</td>\n",
       "      <td>22824.0</td>\n",
       "      <td>22250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01.01.2015 11:00 - 01.01.2015 12:00</td>\n",
       "      <td>23720.0</td>\n",
       "      <td>23547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>01.01.2015 12:00 - 01.01.2015 13:00</td>\n",
       "      <td>24180.0</td>\n",
       "      <td>24133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01.01.2015 13:00 - 01.01.2015 14:00</td>\n",
       "      <td>24797.0</td>\n",
       "      <td>24713.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01.01.2015 14:00 - 01.01.2015 15:00</td>\n",
       "      <td>25222.0</td>\n",
       "      <td>24672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01.01.2015 15:00 - 01.01.2015 16:00</td>\n",
       "      <td>24173.0</td>\n",
       "      <td>23528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01.01.2015 16:00 - 01.01.2015 17:00</td>\n",
       "      <td>23659.0</td>\n",
       "      <td>23118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01.01.2015 17:00 - 01.01.2015 18:00</td>\n",
       "      <td>23982.0</td>\n",
       "      <td>23606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>01.01.2015 18:00 - 01.01.2015 19:00</td>\n",
       "      <td>26981.0</td>\n",
       "      <td>26447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01.01.2015 19:00 - 01.01.2015 20:00</td>\n",
       "      <td>28515.0</td>\n",
       "      <td>28020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>01.01.2015 20:00 - 01.01.2015 21:00</td>\n",
       "      <td>30482.0</td>\n",
       "      <td>29014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01.01.2015 21:00 - 01.01.2015 22:00</td>\n",
       "      <td>30739.0</td>\n",
       "      <td>29571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>01.01.2015 22:00 - 01.01.2015 23:00</td>\n",
       "      <td>29756.0</td>\n",
       "      <td>29031.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01.01.2015 23:00 - 02.01.2015 00:00</td>\n",
       "      <td>27589.0</td>\n",
       "      <td>26798.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Time (CET)  \\\n",
       "0   01.01.2015 00:00 - 01.01.2015 01:00   \n",
       "1   01.01.2015 01:00 - 01.01.2015 02:00   \n",
       "2   01.01.2015 02:00 - 01.01.2015 03:00   \n",
       "3   01.01.2015 03:00 - 01.01.2015 04:00   \n",
       "4   01.01.2015 04:00 - 01.01.2015 05:00   \n",
       "5   01.01.2015 05:00 - 01.01.2015 06:00   \n",
       "6   01.01.2015 06:00 - 01.01.2015 07:00   \n",
       "7   01.01.2015 07:00 - 01.01.2015 08:00   \n",
       "8   01.01.2015 08:00 - 01.01.2015 09:00   \n",
       "9   01.01.2015 09:00 - 01.01.2015 10:00   \n",
       "10  01.01.2015 10:00 - 01.01.2015 11:00   \n",
       "11  01.01.2015 11:00 - 01.01.2015 12:00   \n",
       "12  01.01.2015 12:00 - 01.01.2015 13:00   \n",
       "13  01.01.2015 13:00 - 01.01.2015 14:00   \n",
       "14  01.01.2015 14:00 - 01.01.2015 15:00   \n",
       "15  01.01.2015 15:00 - 01.01.2015 16:00   \n",
       "16  01.01.2015 16:00 - 01.01.2015 17:00   \n",
       "17  01.01.2015 17:00 - 01.01.2015 18:00   \n",
       "18  01.01.2015 18:00 - 01.01.2015 19:00   \n",
       "19  01.01.2015 19:00 - 01.01.2015 20:00   \n",
       "20  01.01.2015 20:00 - 01.01.2015 21:00   \n",
       "21  01.01.2015 21:00 - 01.01.2015 22:00   \n",
       "22  01.01.2015 22:00 - 01.01.2015 23:00   \n",
       "23  01.01.2015 23:00 - 02.01.2015 00:00   \n",
       "\n",
       "    Day-ahead Total Load Forecast [MW] - BZN|ES  \\\n",
       "0                                       26118.0   \n",
       "1                                       24934.0   \n",
       "2                                       23515.0   \n",
       "3                                       22642.0   \n",
       "4                                       21785.0   \n",
       "5                                       21441.0   \n",
       "6                                       21285.0   \n",
       "7                                       21545.0   \n",
       "8                                       21443.0   \n",
       "9                                       21560.0   \n",
       "10                                      22824.0   \n",
       "11                                      23720.0   \n",
       "12                                      24180.0   \n",
       "13                                      24797.0   \n",
       "14                                      25222.0   \n",
       "15                                      24173.0   \n",
       "16                                      23659.0   \n",
       "17                                      23982.0   \n",
       "18                                      26981.0   \n",
       "19                                      28515.0   \n",
       "20                                      30482.0   \n",
       "21                                      30739.0   \n",
       "22                                      29756.0   \n",
       "23                                      27589.0   \n",
       "\n",
       "    Actual Total Load [MW] - BZN|ES  \n",
       "0                           25385.0  \n",
       "1                           24382.0  \n",
       "2                           22734.0  \n",
       "3                           21286.0  \n",
       "4                           20264.0  \n",
       "5                           19905.0  \n",
       "6                           20010.0  \n",
       "7                           20377.0  \n",
       "8                           20094.0  \n",
       "9                           20637.0  \n",
       "10                          22250.0  \n",
       "11                          23547.0  \n",
       "12                          24133.0  \n",
       "13                          24713.0  \n",
       "14                          24672.0  \n",
       "15                          23528.0  \n",
       "16                          23118.0  \n",
       "17                          23606.0  \n",
       "18                          26447.0  \n",
       "19                          28020.0  \n",
       "20                          29014.0  \n",
       "21                          29571.0  \n",
       "22                          29031.0  \n",
       "23                          26798.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inital look at the unprocessed data\n",
    "data_sets[0].head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "    '''\n",
    "    Input: A dataframe of Day Ahead Total Load, and Actual Load obtained from csv data obtained from the entsoe Transparency Platform.\n",
    "    \n",
    "    Descrption:\n",
    "    Input is a 3 column dataframe consisting of text time stamps with hourly frequency. \n",
    "    - Function formats the string in order to be formatted into a datetime.\n",
    "    - Appends a datetime index and drops the time strings\n",
    "    \n",
    "    Output: A 2 column dataframe with a DatetimeIndex\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #set column names to something simple\n",
    "    data.columns = ['time', 'day_forecast',\n",
    "       'actual_load']\n",
    "\n",
    "    #set the time to the first element in the time string. \n",
    "    #So 01.01.2018 00:00 - 01.01.2018 01:00 becomes 01.01.2018 00:00\n",
    "    data['time'] = data['time'].str.split('-').apply(lambda x: x[0]).str.strip()\n",
    "     \n",
    "    #set the time strings to datetime obejects and set index as date time\n",
    "    datetimes = pd.to_datetime(data['time'], format='%d-%m-%Y %H%M', errors='ignore')\n",
    "    data_ = data.set_index(pd.DatetimeIndex(datetimes))\n",
    "    \n",
    "    #remove extra time column with original string objects\n",
    "    data_time = data_[['day_forecast', 'actual_load']]\n",
    "    \n",
    "    return data_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(len(files))\n",
    "\n",
    "#create a dictionary of formatted pandas dataframes where key is each year\n",
    "format_sets = {year: format_data(data_set) for year,data_set in zip(years, data_sets)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_forecast</th>\n",
       "      <th>actual_load</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>23273.0</td>\n",
       "      <td>22431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>22495.0</td>\n",
       "      <td>21632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>21272.0</td>\n",
       "      <td>20357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>20022.0</td>\n",
       "      <td>19152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>19148.0</td>\n",
       "      <td>18310.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     day_forecast  actual_load\n",
       "time                                          \n",
       "2016-01-01 00:00:00       23273.0      22431.0\n",
       "2016-01-01 01:00:00       22495.0      21632.0\n",
       "2016-01-01 02:00:00       21272.0      20357.0\n",
       "2016-01-01 03:00:00       20022.0      19152.0\n",
       "2016-01-01 04:00:00       19148.0      18310.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at the formatted data\n",
    "format_sets[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data into single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_annual_data(dictionary):\n",
    "    \"\"\"\n",
    "    Input: a dictionary of dataframes.\n",
    "    \n",
    "    Output: a single dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    all_data_list = []\n",
    "    \n",
    "    for key in dictionary.keys():\n",
    "        all_data_list.append(dictionary[key])\n",
    "        \n",
    "    data_all_years = pd.concat(all_data_list)\n",
    "    \n",
    "    return data_all_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine into one single dataframe\n",
    "data = combine_annual_data(format_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean NANs\n",
    "\n",
    "This data will be used for predicting day ahead energy demand. In dealing with nan values it is important not to change the structure of the data. \n",
    "\n",
    "Two ways this can occur:\n",
    "   1. dropping values changes number of observations in a day. number of daily observations per day needs to line up with the days before and after.\n",
    "   2. filling missing values with a single value (i.e. series mean value) is not representiative of the temporal nature of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 43829 entries, 2015-01-01 00:00:00 to 2019-12-31 23:00:00\n",
      "Data columns (total 2 columns):\n",
      "day_forecast    43819 non-null object\n",
      "actual_load     43772 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#check for nans in the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data is type object. This likely indicates that there are string objects in the columns. These will have to be converted to nan before nans can be filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(day_forecast    10\n",
       " actual_load     57\n",
       " dtype: int64, 43829)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the total nans in each column and the total length of the data.\n",
    "data.isnull().sum(), len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 3 and 12 nan values respectively in a dataset of length 26307. This is very clean data.\n",
    "\n",
    "Can savfely imput the data with a linear interpolation function without changing the structure of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DatetimeIndex(['2015-02-01 07:00:00', '2015-02-01 08:00:00',\n",
       "                '2015-02-01 09:00:00', '2015-02-01 12:00:00',\n",
       "                '2015-02-01 13:00:00', '2015-02-01 14:00:00',\n",
       "                '2015-02-01 15:00:00', '2015-02-01 16:00:00',\n",
       "                '2015-02-01 17:00:00', '2015-02-01 18:00:00',\n",
       "                '2015-02-01 19:00:00', '2015-01-28 13:00:00',\n",
       "                '2015-05-02 10:00:00', '2015-10-02 08:00:00',\n",
       "                '2015-10-02 11:00:00', '2015-12-02 09:00:00',\n",
       "                '2015-03-29 02:00:00', '2015-04-16 09:00:00',\n",
       "                '2015-04-20 08:00:00', '2015-04-23 21:00:00',\n",
       "                '2015-01-05 12:00:00', '2015-01-05 13:00:00',\n",
       "                '2015-01-05 14:00:00', '2015-01-05 15:00:00',\n",
       "                '2015-01-05 16:00:00', '2015-01-05 17:00:00',\n",
       "                '2015-04-05 03:00:00', '2015-05-29 03:00:00',\n",
       "                '2016-03-27 02:00:00', '2016-04-25 05:00:00',\n",
       "                '2016-04-25 07:00:00', '2016-07-09 22:00:00',\n",
       "                '2016-09-28 09:00:00', '2016-05-10 23:00:00',\n",
       "                '2017-03-26 02:00:00', '2017-11-14 12:00:00',\n",
       "                '2017-11-14 19:00:00', '2018-03-25 02:00:00',\n",
       "                '2018-06-11 18:00:00', '2018-07-11 09:00:00',\n",
       "                '2019-03-31 02:00:00', '2019-09-08 16:00:00',\n",
       "                '2019-09-08 17:00:00', '2019-09-08 18:00:00',\n",
       "                '2019-09-08 19:00:00', '2019-09-08 20:00:00',\n",
       "                '2019-09-08 21:00:00', '2019-09-08 22:00:00',\n",
       "                '2019-09-08 23:00:00', '2019-10-08 11:00:00',\n",
       "                '2019-10-08 12:00:00', '2019-10-08 13:00:00',\n",
       "                '2019-10-08 14:00:00', '2019-10-08 15:00:00',\n",
       "                '2019-10-08 16:00:00', '2019-10-08 17:00:00',\n",
       "                '2019-10-08 18:00:00'],\n",
       "               dtype='datetime64[ns]', name='time', freq=None),\n",
       " DatetimeIndex(['2015-03-29 02:00:00', '2016-03-27 02:00:00',\n",
       "                '2017-03-26 02:00:00', '2018-03-25 02:00:00',\n",
       "                '2019-03-31 02:00:00', '2019-08-31 00:00:00',\n",
       "                '2019-08-31 01:00:00', '2019-08-31 02:00:00',\n",
       "                '2019-08-31 03:00:00', '2019-08-31 04:00:00'],\n",
       "               dtype='datetime64[ns]', name='time', freq=None))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#isolate the row indexes that with Nans\n",
    "#use this to check the repalce_nans function works\n",
    "nan_load = data[data['actual_load'].isnull()==True].index\n",
    "nan_forecast = data[data['day_forecast'].isnull()==True].index\n",
    "(nan_load, nan_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_nans(data):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    - data --- a dataframe of timeseries data\n",
    "    - columns --- a list of column header names\n",
    "    \n",
    "    Process:\n",
    "    Applies linear interpolation to fill the missing entries per column\n",
    "    \n",
    "    output: a dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        data = data.astype(float)\n",
    "    except:\n",
    "        for char in ['-', '--', '?']:\n",
    "            data = data.replace('-', np.nan)\n",
    "        data = data.astype(float)\n",
    "    \n",
    "    data = data.interpolate(method='linear', axis=0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_forecast</th>\n",
       "      <th>actual_load</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [day_forecast, actual_load]\n",
       "Index: []"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = interpolate_nans(data)\n",
    "\n",
    "#check the function works\n",
    "data[data['actual_load'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 40780 entries, 2015-01-01 00:00:00 to 2019-08-12 23:00:00\n",
      "Data columns (total 2 columns):\n",
      "day_forecast    40780 non-null float64\n",
      "actual_load     40780 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 955.8 KB\n"
     ]
    }
   ],
   "source": [
    "#also see that the columns are now floats\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-02-01 07:00:00       24379.0      24710.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-02-01 08:00:00       27389.0      27268.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-02-01 09:00:00       30619.0      29825.5\n",
      "                     day_forecast   actual_load\n",
      "time                                           \n",
      "2015-02-01 12:00:00       31357.0  32535.444444\n",
      "                     day_forecast   actual_load\n",
      "time                                           \n",
      "2015-02-01 13:00:00       31338.0  32712.888889\n",
      "                     day_forecast   actual_load\n",
      "time                                           \n",
      "2015-02-01 14:00:00       30874.0  32890.333333\n",
      "                     day_forecast   actual_load\n",
      "time                                           \n",
      "2015-02-01 15:00:00       30124.0  33067.777778\n",
      "                     day_forecast   actual_load\n",
      "time                                           \n",
      "2015-02-01 16:00:00       29714.0  33245.222222\n",
      "                     day_forecast   actual_load\n",
      "time                                           \n",
      "2015-02-01 17:00:00       29801.0  33422.666667\n",
      "                     day_forecast   actual_load\n",
      "time                                           \n",
      "2015-02-01 18:00:00       32257.0  33600.111111\n",
      "                     day_forecast   actual_load\n",
      "time                                           \n",
      "2015-02-01 19:00:00       33183.0  33777.555556\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-01-28 13:00:00       36239.0      35191.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-05-02 10:00:00       39644.0      38289.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-10-02 08:00:00       36798.0      36145.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-10-02 11:00:00       38921.0      38407.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-12-02 09:00:00       37413.0      36809.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-03-29 02:00:00       21701.5      21514.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-04-16 09:00:00       31001.0      28004.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-04-20 08:00:00       29287.0      28595.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-04-23 21:00:00       31421.0      28759.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-01-05 12:00:00       23209.0      24066.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-01-05 13:00:00       23725.0      23703.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-01-05 14:00:00       23614.0      23340.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-01-05 15:00:00       22381.0      22977.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-01-05 16:00:00       21371.0      22614.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-01-05 17:00:00       20760.0      22251.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-04-05 03:00:00       20016.0      20582.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2015-05-29 03:00:00       23132.0      23337.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-03-27 02:00:00       21388.0      21626.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-04-25 05:00:00       21471.0      22528.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-04-25 07:00:00       27635.0      26928.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-07-09 22:00:00       34985.0      34263.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-09-28 09:00:00       31072.0      31597.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2016-05-10 23:00:00       26641.0      27519.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2017-03-26 02:00:00       22504.0      22967.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2017-11-14 12:00:00       33805.0      33970.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2017-11-14 19:00:00       35592.0      35709.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2018-03-25 02:00:00       23295.0      23999.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2018-06-11 18:00:00       34752.0      34186.0\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2018-07-11 09:00:00       33938.0      33492.5\n",
      "                     day_forecast  actual_load\n",
      "time                                          \n",
      "2019-03-31 02:00:00       21628.0      21925.0\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [day_forecast, actual_load]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#take a look at the interpreted values and see how they compare to the values around them.\n",
    "for t in nan_load:\n",
    "    print(data[str(t)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicated timestamps\n",
    "\n",
    "Because we are working with sequence data, it is important that there are the correct number of values per 24 hour period. If not, the data could at some point offset and become a source of error for the model.\n",
    "\n",
    "In this case each day is 24 hours, and contains 24 readings. Therefore we can calculate how many data points we should have in a given period.\n",
    "\n",
    "I.e. for the 5 year period cleaned in this example we have the years 2015, 2017, 2018, 2019 as non leap years, while 2016 is, so we have to account for it. Therefore (365 x 2 + 366) x 24 = 26304 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "43829\n"
     ]
    }
   ],
   "source": [
    "print(len(data)==26304)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we have 3 duplicated entries. Drop the extra values and take the first occurance of the data point by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicated_rows(data):\n",
    "    \"\"\"\n",
    "    Input a timeseries dataset with multiple rows of the same index value.\n",
    "    \n",
    "    Output timeseries dataset with first occurance of duplicated rows.\n",
    "    \"\"\"\n",
    "    #identify the duplicated elements\n",
    "    duplicated_rows_bool = data.index.duplicated()\n",
    "    \n",
    "    #invert the array element wise\n",
    "    keep_rows = np.invert(duplicated_rows_bool)\n",
    "    \n",
    "    #return the original dataframe removing the duplicated values\n",
    "    return data[keep_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26304"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = remove_duplicated_rows(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data now lines up with the expected number of observations and may be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the prepared data as csv\n",
    "save_path = './data/processed_data/'\n",
    "data.to_csv(save_path + 'load_forecast_2016_2018.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
