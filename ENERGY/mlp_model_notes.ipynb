{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_model_notes.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SHgBeKgpEix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cb27f09-7a0e-46ee-e052-18358cf1f16e"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-alpha0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q6eIfaCpaWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "b1ab7570-800e-4650-db63-6f66415db1ce"
      },
      "source": [
        "pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.1.7)\n",
            "Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.16.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (0.33.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.1.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVOmqSrkphPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX7cvq3IqvdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "84d69c29-7f1a-4baf-e416-9190e351a253"
      },
      "source": [
        "! git clone https://github.com/nicholasjhana/short-term-energy-demand-forecasting.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'short-term-energy-demand-forecasting'...\n",
            "remote: Enumerating objects: 174, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 174 (delta 87), reused 123 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (174/174), 8.25 MiB | 5.09 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAECu6uzrHqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "16361f67-187a-4a9e-c3ec-6eb0310b6629"
      },
      "source": [
        "!ls -l short-term-energy-demand-forecasting/data/processed/transformed_2016_2018.csv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1452\n",
            "-rw-r--r-- 1 root root   34805 Aug 31 12:35 holidays_data_daily.csv\n",
            "-rw-r--r-- 1 root root 1445925 Aug 31 12:35 transformed_2016_2018.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiRMQ7tCrM1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cBmUxnDrcQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('short-term-energy-demand-forecasting/data/processed/energy_min_features.csv', parse_dates=True, index_col='date')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMeOLZkBrk2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "765627db-15ee-448d-d9c4-c2d208454ae4"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>t-0 h_0</th>\n",
              "      <th>t-0 h_1</th>\n",
              "      <th>t-0 h_2</th>\n",
              "      <th>t-0 h_3</th>\n",
              "      <th>t-0 h_4</th>\n",
              "      <th>t-0 h_5</th>\n",
              "      <th>t-0 h_6</th>\n",
              "      <th>t-0 h_7</th>\n",
              "      <th>t-0 h_8</th>\n",
              "      <th>t-0 h_9</th>\n",
              "      <th>t-0 h_10</th>\n",
              "      <th>t-0 h_11</th>\n",
              "      <th>t-0 h_12</th>\n",
              "      <th>t-0 h_13</th>\n",
              "      <th>t-0 h_14</th>\n",
              "      <th>t-0 h_15</th>\n",
              "      <th>t-0 h_16</th>\n",
              "      <th>t-0 h_17</th>\n",
              "      <th>t-0 h_18</th>\n",
              "      <th>t-0 h_19</th>\n",
              "      <th>t-0 h_20</th>\n",
              "      <th>t-0 h_21</th>\n",
              "      <th>t-0 h_22</th>\n",
              "      <th>t-0 h_23</th>\n",
              "      <th>t-1 h_0</th>\n",
              "      <th>t-1 h_1</th>\n",
              "      <th>t-1 h_2</th>\n",
              "      <th>t-1 h_3</th>\n",
              "      <th>t-1 h_4</th>\n",
              "      <th>t-1 h_5</th>\n",
              "      <th>t-1 h_6</th>\n",
              "      <th>t-1 h_7</th>\n",
              "      <th>t-1 h_8</th>\n",
              "      <th>t-1 h_9</th>\n",
              "      <th>t-1 h_10</th>\n",
              "      <th>t-1 h_11</th>\n",
              "      <th>t-1 h_12</th>\n",
              "      <th>t-1 h_13</th>\n",
              "      <th>t-1 h_14</th>\n",
              "      <th>t-1 h_15</th>\n",
              "      <th>...</th>\n",
              "      <th>t-3 h_8</th>\n",
              "      <th>t-3 h_9</th>\n",
              "      <th>t-3 h_10</th>\n",
              "      <th>t-3 h_11</th>\n",
              "      <th>t-3 h_12</th>\n",
              "      <th>t-3 h_13</th>\n",
              "      <th>t-3 h_14</th>\n",
              "      <th>t-3 h_15</th>\n",
              "      <th>t-3 h_16</th>\n",
              "      <th>t-3 h_17</th>\n",
              "      <th>t-3 h_18</th>\n",
              "      <th>t-3 h_19</th>\n",
              "      <th>t-3 h_20</th>\n",
              "      <th>t-3 h_21</th>\n",
              "      <th>t-3 h_22</th>\n",
              "      <th>t-3 h_23</th>\n",
              "      <th>t-4 h_0</th>\n",
              "      <th>t-4 h_1</th>\n",
              "      <th>t-4 h_2</th>\n",
              "      <th>t-4 h_3</th>\n",
              "      <th>t-4 h_4</th>\n",
              "      <th>t-4 h_5</th>\n",
              "      <th>t-4 h_6</th>\n",
              "      <th>t-4 h_7</th>\n",
              "      <th>t-4 h_8</th>\n",
              "      <th>t-4 h_9</th>\n",
              "      <th>t-4 h_10</th>\n",
              "      <th>t-4 h_11</th>\n",
              "      <th>t-4 h_12</th>\n",
              "      <th>t-4 h_13</th>\n",
              "      <th>t-4 h_14</th>\n",
              "      <th>t-4 h_15</th>\n",
              "      <th>t-4 h_16</th>\n",
              "      <th>t-4 h_17</th>\n",
              "      <th>t-4 h_18</th>\n",
              "      <th>t-4 h_19</th>\n",
              "      <th>t-4 h_20</th>\n",
              "      <th>t-4 h_21</th>\n",
              "      <th>t-4 h_22</th>\n",
              "      <th>t-4 h_23</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-05</th>\n",
              "      <td>23642.0</td>\n",
              "      <td>21990.0</td>\n",
              "      <td>20629.0</td>\n",
              "      <td>19865.0</td>\n",
              "      <td>19446.0</td>\n",
              "      <td>19248.0</td>\n",
              "      <td>19296.0</td>\n",
              "      <td>18956.0</td>\n",
              "      <td>20072.0</td>\n",
              "      <td>21911.0</td>\n",
              "      <td>23473.0</td>\n",
              "      <td>23991.0</td>\n",
              "      <td>23961.0</td>\n",
              "      <td>23883.0</td>\n",
              "      <td>23378.0</td>\n",
              "      <td>22190.0</td>\n",
              "      <td>21549.0</td>\n",
              "      <td>21233.0</td>\n",
              "      <td>21298.0</td>\n",
              "      <td>21756.0</td>\n",
              "      <td>22929.0</td>\n",
              "      <td>25815.0</td>\n",
              "      <td>25843.0</td>\n",
              "      <td>24167.0</td>\n",
              "      <td>26751.0</td>\n",
              "      <td>24882.0</td>\n",
              "      <td>23736.0</td>\n",
              "      <td>23199.0</td>\n",
              "      <td>23000.0</td>\n",
              "      <td>23348.0</td>\n",
              "      <td>25748.0</td>\n",
              "      <td>29620.0</td>\n",
              "      <td>31776.0</td>\n",
              "      <td>33087.0</td>\n",
              "      <td>33719.0</td>\n",
              "      <td>33669.0</td>\n",
              "      <td>33521.0</td>\n",
              "      <td>32874.0</td>\n",
              "      <td>31594.0</td>\n",
              "      <td>30376.0</td>\n",
              "      <td>...</td>\n",
              "      <td>33164.0</td>\n",
              "      <td>34001.0</td>\n",
              "      <td>34176.0</td>\n",
              "      <td>33919.0</td>\n",
              "      <td>33593.0</td>\n",
              "      <td>33310.0</td>\n",
              "      <td>32099.0</td>\n",
              "      <td>31449.0</td>\n",
              "      <td>31179.0</td>\n",
              "      <td>31175.0</td>\n",
              "      <td>32515.0</td>\n",
              "      <td>34967.0</td>\n",
              "      <td>35381.0</td>\n",
              "      <td>34700.0</td>\n",
              "      <td>32055.0</td>\n",
              "      <td>28939.0</td>\n",
              "      <td>22431.0</td>\n",
              "      <td>21632.0</td>\n",
              "      <td>20357.0</td>\n",
              "      <td>19152.0</td>\n",
              "      <td>18310.0</td>\n",
              "      <td>18054.0</td>\n",
              "      <td>18234.0</td>\n",
              "      <td>18596.0</td>\n",
              "      <td>18541.0</td>\n",
              "      <td>18942.0</td>\n",
              "      <td>20484.0</td>\n",
              "      <td>21805.0</td>\n",
              "      <td>22607.0</td>\n",
              "      <td>23178.0</td>\n",
              "      <td>23265.0</td>\n",
              "      <td>22061.0</td>\n",
              "      <td>21481.0</td>\n",
              "      <td>21830.0</td>\n",
              "      <td>24291.0</td>\n",
              "      <td>25234.0</td>\n",
              "      <td>25881.0</td>\n",
              "      <td>26149.0</td>\n",
              "      <td>25610.0</td>\n",
              "      <td>24000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-06</th>\n",
              "      <td>25135.0</td>\n",
              "      <td>23717.0</td>\n",
              "      <td>22747.0</td>\n",
              "      <td>22440.0</td>\n",
              "      <td>22396.0</td>\n",
              "      <td>22737.0</td>\n",
              "      <td>24350.0</td>\n",
              "      <td>26788.0</td>\n",
              "      <td>28705.0</td>\n",
              "      <td>30029.0</td>\n",
              "      <td>30655.0</td>\n",
              "      <td>31057.0</td>\n",
              "      <td>31466.0</td>\n",
              "      <td>31369.0</td>\n",
              "      <td>30470.0</td>\n",
              "      <td>29970.0</td>\n",
              "      <td>29979.0</td>\n",
              "      <td>29924.0</td>\n",
              "      <td>29640.0</td>\n",
              "      <td>29409.0</td>\n",
              "      <td>29484.0</td>\n",
              "      <td>30027.0</td>\n",
              "      <td>29332.0</td>\n",
              "      <td>26854.0</td>\n",
              "      <td>23642.0</td>\n",
              "      <td>21990.0</td>\n",
              "      <td>20629.0</td>\n",
              "      <td>19865.0</td>\n",
              "      <td>19446.0</td>\n",
              "      <td>19248.0</td>\n",
              "      <td>19296.0</td>\n",
              "      <td>18956.0</td>\n",
              "      <td>20072.0</td>\n",
              "      <td>21911.0</td>\n",
              "      <td>23473.0</td>\n",
              "      <td>23991.0</td>\n",
              "      <td>23961.0</td>\n",
              "      <td>23883.0</td>\n",
              "      <td>23378.0</td>\n",
              "      <td>22190.0</td>\n",
              "      <td>...</td>\n",
              "      <td>34093.0</td>\n",
              "      <td>35371.0</td>\n",
              "      <td>35678.0</td>\n",
              "      <td>35221.0</td>\n",
              "      <td>34751.0</td>\n",
              "      <td>34335.0</td>\n",
              "      <td>33029.0</td>\n",
              "      <td>32344.0</td>\n",
              "      <td>31927.0</td>\n",
              "      <td>31824.0</td>\n",
              "      <td>32226.0</td>\n",
              "      <td>35161.0</td>\n",
              "      <td>36599.0</td>\n",
              "      <td>35729.0</td>\n",
              "      <td>33154.0</td>\n",
              "      <td>29838.0</td>\n",
              "      <td>24937.0</td>\n",
              "      <td>23121.0</td>\n",
              "      <td>22101.0</td>\n",
              "      <td>21718.0</td>\n",
              "      <td>21760.0</td>\n",
              "      <td>22695.0</td>\n",
              "      <td>25689.0</td>\n",
              "      <td>30493.0</td>\n",
              "      <td>33164.0</td>\n",
              "      <td>34001.0</td>\n",
              "      <td>34176.0</td>\n",
              "      <td>33919.0</td>\n",
              "      <td>33593.0</td>\n",
              "      <td>33310.0</td>\n",
              "      <td>32099.0</td>\n",
              "      <td>31449.0</td>\n",
              "      <td>31179.0</td>\n",
              "      <td>31175.0</td>\n",
              "      <td>32515.0</td>\n",
              "      <td>34967.0</td>\n",
              "      <td>35381.0</td>\n",
              "      <td>34700.0</td>\n",
              "      <td>32055.0</td>\n",
              "      <td>28939.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-07</th>\n",
              "      <td>28425.0</td>\n",
              "      <td>26609.0</td>\n",
              "      <td>25442.0</td>\n",
              "      <td>24864.0</td>\n",
              "      <td>24609.0</td>\n",
              "      <td>24776.0</td>\n",
              "      <td>26062.0</td>\n",
              "      <td>28023.0</td>\n",
              "      <td>30354.0</td>\n",
              "      <td>32641.0</td>\n",
              "      <td>33925.0</td>\n",
              "      <td>34542.0</td>\n",
              "      <td>35364.0</td>\n",
              "      <td>35804.0</td>\n",
              "      <td>34702.0</td>\n",
              "      <td>33939.0</td>\n",
              "      <td>33753.0</td>\n",
              "      <td>33510.0</td>\n",
              "      <td>33079.0</td>\n",
              "      <td>32697.0</td>\n",
              "      <td>32172.0</td>\n",
              "      <td>31560.0</td>\n",
              "      <td>30943.0</td>\n",
              "      <td>29025.0</td>\n",
              "      <td>25135.0</td>\n",
              "      <td>23717.0</td>\n",
              "      <td>22747.0</td>\n",
              "      <td>22440.0</td>\n",
              "      <td>22396.0</td>\n",
              "      <td>22737.0</td>\n",
              "      <td>24350.0</td>\n",
              "      <td>26788.0</td>\n",
              "      <td>28705.0</td>\n",
              "      <td>30029.0</td>\n",
              "      <td>30655.0</td>\n",
              "      <td>31057.0</td>\n",
              "      <td>31466.0</td>\n",
              "      <td>31369.0</td>\n",
              "      <td>30470.0</td>\n",
              "      <td>29970.0</td>\n",
              "      <td>...</td>\n",
              "      <td>31776.0</td>\n",
              "      <td>33087.0</td>\n",
              "      <td>33719.0</td>\n",
              "      <td>33669.0</td>\n",
              "      <td>33521.0</td>\n",
              "      <td>32874.0</td>\n",
              "      <td>31594.0</td>\n",
              "      <td>30376.0</td>\n",
              "      <td>29915.0</td>\n",
              "      <td>29633.0</td>\n",
              "      <td>29158.0</td>\n",
              "      <td>29159.0</td>\n",
              "      <td>30469.0</td>\n",
              "      <td>32482.0</td>\n",
              "      <td>30508.0</td>\n",
              "      <td>28598.0</td>\n",
              "      <td>27227.0</td>\n",
              "      <td>25292.0</td>\n",
              "      <td>24265.0</td>\n",
              "      <td>23774.0</td>\n",
              "      <td>23650.0</td>\n",
              "      <td>24275.0</td>\n",
              "      <td>27243.0</td>\n",
              "      <td>31518.0</td>\n",
              "      <td>34093.0</td>\n",
              "      <td>35371.0</td>\n",
              "      <td>35678.0</td>\n",
              "      <td>35221.0</td>\n",
              "      <td>34751.0</td>\n",
              "      <td>34335.0</td>\n",
              "      <td>33029.0</td>\n",
              "      <td>32344.0</td>\n",
              "      <td>31927.0</td>\n",
              "      <td>31824.0</td>\n",
              "      <td>32226.0</td>\n",
              "      <td>35161.0</td>\n",
              "      <td>36599.0</td>\n",
              "      <td>35729.0</td>\n",
              "      <td>33154.0</td>\n",
              "      <td>29838.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-08</th>\n",
              "      <td>26986.0</td>\n",
              "      <td>25125.0</td>\n",
              "      <td>23969.0</td>\n",
              "      <td>23281.0</td>\n",
              "      <td>23088.0</td>\n",
              "      <td>23573.0</td>\n",
              "      <td>25487.0</td>\n",
              "      <td>27299.0</td>\n",
              "      <td>29776.0</td>\n",
              "      <td>31487.0</td>\n",
              "      <td>33239.0</td>\n",
              "      <td>34169.0</td>\n",
              "      <td>35215.0</td>\n",
              "      <td>35892.0</td>\n",
              "      <td>35288.0</td>\n",
              "      <td>34479.0</td>\n",
              "      <td>34240.0</td>\n",
              "      <td>34101.0</td>\n",
              "      <td>33693.0</td>\n",
              "      <td>32919.0</td>\n",
              "      <td>32267.0</td>\n",
              "      <td>32709.0</td>\n",
              "      <td>32355.0</td>\n",
              "      <td>29998.0</td>\n",
              "      <td>28425.0</td>\n",
              "      <td>26609.0</td>\n",
              "      <td>25442.0</td>\n",
              "      <td>24864.0</td>\n",
              "      <td>24609.0</td>\n",
              "      <td>24776.0</td>\n",
              "      <td>26062.0</td>\n",
              "      <td>28023.0</td>\n",
              "      <td>30354.0</td>\n",
              "      <td>32641.0</td>\n",
              "      <td>33925.0</td>\n",
              "      <td>34542.0</td>\n",
              "      <td>35364.0</td>\n",
              "      <td>35804.0</td>\n",
              "      <td>34702.0</td>\n",
              "      <td>33939.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20072.0</td>\n",
              "      <td>21911.0</td>\n",
              "      <td>23473.0</td>\n",
              "      <td>23991.0</td>\n",
              "      <td>23961.0</td>\n",
              "      <td>23883.0</td>\n",
              "      <td>23378.0</td>\n",
              "      <td>22190.0</td>\n",
              "      <td>21549.0</td>\n",
              "      <td>21233.0</td>\n",
              "      <td>21298.0</td>\n",
              "      <td>21756.0</td>\n",
              "      <td>22929.0</td>\n",
              "      <td>25815.0</td>\n",
              "      <td>25843.0</td>\n",
              "      <td>24167.0</td>\n",
              "      <td>26751.0</td>\n",
              "      <td>24882.0</td>\n",
              "      <td>23736.0</td>\n",
              "      <td>23199.0</td>\n",
              "      <td>23000.0</td>\n",
              "      <td>23348.0</td>\n",
              "      <td>25748.0</td>\n",
              "      <td>29620.0</td>\n",
              "      <td>31776.0</td>\n",
              "      <td>33087.0</td>\n",
              "      <td>33719.0</td>\n",
              "      <td>33669.0</td>\n",
              "      <td>33521.0</td>\n",
              "      <td>32874.0</td>\n",
              "      <td>31594.0</td>\n",
              "      <td>30376.0</td>\n",
              "      <td>29915.0</td>\n",
              "      <td>29633.0</td>\n",
              "      <td>29158.0</td>\n",
              "      <td>29159.0</td>\n",
              "      <td>30469.0</td>\n",
              "      <td>32482.0</td>\n",
              "      <td>30508.0</td>\n",
              "      <td>28598.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-09</th>\n",
              "      <td>28284.0</td>\n",
              "      <td>26487.0</td>\n",
              "      <td>25264.0</td>\n",
              "      <td>24744.0</td>\n",
              "      <td>24505.0</td>\n",
              "      <td>24766.0</td>\n",
              "      <td>26459.0</td>\n",
              "      <td>28734.0</td>\n",
              "      <td>30505.0</td>\n",
              "      <td>32582.0</td>\n",
              "      <td>34111.0</td>\n",
              "      <td>35067.0</td>\n",
              "      <td>36201.0</td>\n",
              "      <td>36769.0</td>\n",
              "      <td>36004.0</td>\n",
              "      <td>35417.0</td>\n",
              "      <td>35492.0</td>\n",
              "      <td>35529.0</td>\n",
              "      <td>34992.0</td>\n",
              "      <td>34052.0</td>\n",
              "      <td>33899.0</td>\n",
              "      <td>34957.0</td>\n",
              "      <td>32547.0</td>\n",
              "      <td>30096.0</td>\n",
              "      <td>26986.0</td>\n",
              "      <td>25125.0</td>\n",
              "      <td>23969.0</td>\n",
              "      <td>23281.0</td>\n",
              "      <td>23088.0</td>\n",
              "      <td>23573.0</td>\n",
              "      <td>25487.0</td>\n",
              "      <td>27299.0</td>\n",
              "      <td>29776.0</td>\n",
              "      <td>31487.0</td>\n",
              "      <td>33239.0</td>\n",
              "      <td>34169.0</td>\n",
              "      <td>35215.0</td>\n",
              "      <td>35892.0</td>\n",
              "      <td>35288.0</td>\n",
              "      <td>34479.0</td>\n",
              "      <td>...</td>\n",
              "      <td>28705.0</td>\n",
              "      <td>30029.0</td>\n",
              "      <td>30655.0</td>\n",
              "      <td>31057.0</td>\n",
              "      <td>31466.0</td>\n",
              "      <td>31369.0</td>\n",
              "      <td>30470.0</td>\n",
              "      <td>29970.0</td>\n",
              "      <td>29979.0</td>\n",
              "      <td>29924.0</td>\n",
              "      <td>29640.0</td>\n",
              "      <td>29409.0</td>\n",
              "      <td>29484.0</td>\n",
              "      <td>30027.0</td>\n",
              "      <td>29332.0</td>\n",
              "      <td>26854.0</td>\n",
              "      <td>23642.0</td>\n",
              "      <td>21990.0</td>\n",
              "      <td>20629.0</td>\n",
              "      <td>19865.0</td>\n",
              "      <td>19446.0</td>\n",
              "      <td>19248.0</td>\n",
              "      <td>19296.0</td>\n",
              "      <td>18956.0</td>\n",
              "      <td>20072.0</td>\n",
              "      <td>21911.0</td>\n",
              "      <td>23473.0</td>\n",
              "      <td>23991.0</td>\n",
              "      <td>23961.0</td>\n",
              "      <td>23883.0</td>\n",
              "      <td>23378.0</td>\n",
              "      <td>22190.0</td>\n",
              "      <td>21549.0</td>\n",
              "      <td>21233.0</td>\n",
              "      <td>21298.0</td>\n",
              "      <td>21756.0</td>\n",
              "      <td>22929.0</td>\n",
              "      <td>25815.0</td>\n",
              "      <td>25843.0</td>\n",
              "      <td>24167.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 120 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            t-0 h_0  t-0 h_1  t-0 h_2  ...  t-4 h_21  t-4 h_22  t-4 h_23\n",
              "date                                   ...                              \n",
              "2016-01-05  23642.0  21990.0  20629.0  ...   26149.0   25610.0   24000.0\n",
              "2016-01-06  25135.0  23717.0  22747.0  ...   34700.0   32055.0   28939.0\n",
              "2016-01-07  28425.0  26609.0  25442.0  ...   35729.0   33154.0   29838.0\n",
              "2016-01-08  26986.0  25125.0  23969.0  ...   32482.0   30508.0   28598.0\n",
              "2016-01-09  28284.0  26487.0  25264.0  ...   25815.0   25843.0   24167.0\n",
              "\n",
              "[5 rows x 120 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btUeBqVmyPLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### extract only hour 0 and work with a single hourly slice\n",
        "X_h0, Y_h0 = np.array(data[['t-1 h_0', 't-2 h_0', 't-3 h_0']]), np.array(data['t-0 h_0'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZHPmfX5zOKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "67bd6c86-b237-47ee-fc06-5b8e376b4f92"
      },
      "source": [
        "X_h0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26751., 27227., 24937.],\n",
              "       [23642., 26751., 27227.],\n",
              "       [25135., 23642., 26751.],\n",
              "       ...,\n",
              "       [25147., 24679., 22138.],\n",
              "       [25709., 25147., 24679.],\n",
              "       [24922., 25709., 25147.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFPbaPPx0LJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06bdf56a-fdf1-4aed-8bb4-26b1c258401f"
      },
      "source": [
        "Y_h0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23642., 25135., 28425., ..., 25709., 24922., 24312.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6ZU2kOegxdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4729125-1fd8-4434-af04-bf65ca659f44"
      },
      "source": [
        "X_h0.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1092, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IvcLlQNoLxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4XO47DaoLnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKuozVjM6pIs",
        "colab_type": "text"
      },
      "source": [
        "# Univariate\n",
        "\n",
        "X is 3 lag terms used to predict Y\n",
        "\n",
        "X t-1, t-2, t-3\n",
        "\n",
        "Y = t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn9QR4EjoLcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEYHjUJigohl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the test and train\n",
        "split = int(X_h0.shape[0] * 0.8)\n",
        "X_train_h0, X_test_h0 = X_h0[:split, :], X_h0[split:, :]\n",
        "Y_train_h0, Y_test_h0 = Y_h0[:split], Y_h0[:split]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWeDga6BgoD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddf9ab84-daf4-41db-f0f8-18a7a2e9e3b8"
      },
      "source": [
        "scaler_x, scaler_y, scaler_x_test= MinMaxScaler(), MinMaxScaler(), MinMaxScaler()\n",
        "scaler_x.fit(X_train_h0)\n",
        "scaler_y.fit(np.reshape(Y_train_h0, (-1,1)))\n",
        "scaler_x_test.fit(X_test_h0)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler(copy=True, feature_range=(0, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQtVy5ANgoA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_h0_f = scaler_x.transform(X_train_h0)\n",
        "Y_train_h0_f = scaler_y.transform(np.reshape(Y_train_h0, (-1,1)))\n",
        "X_test_h0_f = scaler_x_test.transform(X_test_h0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJvJFGdmpN0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "05754405-563b-4489-ee32-85717b8f8ac3"
      },
      "source": [
        "X_train_h0_f"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.20970123,  0.4686146 , -0.78047722],\n",
              "       [-1.48726376,  0.20882352,  0.46899858],\n",
              "       [-0.6723494 , -1.48800519,  0.20928221],\n",
              "       ...,\n",
              "       [-0.47530715, -0.79486513, -1.6867564 ],\n",
              "       [-0.32738901, -0.47612985, -0.79411779],\n",
              "       [-0.28208567, -0.32822359, -0.47547418]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLfZ6c4WgEPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmkgoNXUfY22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=3)) \n",
        "model.add(Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yscZCmxii0xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch : 1e-8 * 10**(epoch/10))\n",
        "\n",
        "optimizer = optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhi6OtXAitZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer, loss='mae')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRFFwh2Bgdgg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64e32693-373a-4011-9aee-710f0dd63a94"
      },
      "source": [
        "history = model.fit(X_train_h0_f, Y_train_h0_f, epochs = 1000)#, callbacks=[lr_schedule])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "873/873 [==============================] - 0s 100us/sample - loss: 15.4966\n",
            "Epoch 2/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 15.4826\n",
            "Epoch 3/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 15.4686\n",
            "Epoch 4/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 15.4546\n",
            "Epoch 5/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 15.4406\n",
            "Epoch 6/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 15.4266\n",
            "Epoch 7/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 15.4126\n",
            "Epoch 8/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 15.3986\n",
            "Epoch 9/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 15.3846\n",
            "Epoch 10/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 15.3707\n",
            "Epoch 11/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 15.3567\n",
            "Epoch 12/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 15.3427\n",
            "Epoch 13/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 15.3287\n",
            "Epoch 14/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 15.3147\n",
            "Epoch 15/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 15.3007\n",
            "Epoch 16/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 15.2867\n",
            "Epoch 17/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 15.2727\n",
            "Epoch 18/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 15.2587\n",
            "Epoch 19/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 15.2447\n",
            "Epoch 20/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 15.2307\n",
            "Epoch 21/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 15.2167\n",
            "Epoch 22/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 15.2027\n",
            "Epoch 23/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 15.1888\n",
            "Epoch 24/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 15.1748\n",
            "Epoch 25/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 15.1608\n",
            "Epoch 26/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 15.1468\n",
            "Epoch 27/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 15.1328\n",
            "Epoch 28/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 15.1188\n",
            "Epoch 29/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 15.1048\n",
            "Epoch 30/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 15.0908\n",
            "Epoch 31/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 15.0768\n",
            "Epoch 32/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 15.0628\n",
            "Epoch 33/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 15.0488\n",
            "Epoch 34/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 15.0348\n",
            "Epoch 35/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 15.0208\n",
            "Epoch 36/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 15.0069\n",
            "Epoch 37/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.9929\n",
            "Epoch 38/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 14.9789\n",
            "Epoch 39/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.9649\n",
            "Epoch 40/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.9509\n",
            "Epoch 41/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 14.9369\n",
            "Epoch 42/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.9229\n",
            "Epoch 43/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.9089\n",
            "Epoch 44/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.8949\n",
            "Epoch 45/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.8809\n",
            "Epoch 46/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 14.8669\n",
            "Epoch 47/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 14.8529\n",
            "Epoch 48/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.8389\n",
            "Epoch 49/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 14.8250\n",
            "Epoch 50/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.8110\n",
            "Epoch 51/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 14.7970\n",
            "Epoch 52/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.7830\n",
            "Epoch 53/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.7690\n",
            "Epoch 54/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.7550\n",
            "Epoch 55/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.7410\n",
            "Epoch 56/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 14.7270\n",
            "Epoch 57/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 14.7130\n",
            "Epoch 58/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.6990\n",
            "Epoch 59/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.6850\n",
            "Epoch 60/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.6710\n",
            "Epoch 61/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.6570\n",
            "Epoch 62/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 14.6431\n",
            "Epoch 63/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 14.6291\n",
            "Epoch 64/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.6151\n",
            "Epoch 65/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.6011\n",
            "Epoch 66/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.5871\n",
            "Epoch 67/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.5731\n",
            "Epoch 68/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.5591\n",
            "Epoch 69/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 14.5451\n",
            "Epoch 70/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 14.5311\n",
            "Epoch 71/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 14.5171\n",
            "Epoch 72/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.5031\n",
            "Epoch 73/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.4891\n",
            "Epoch 74/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 14.4751\n",
            "Epoch 75/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.4612\n",
            "Epoch 76/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.4472\n",
            "Epoch 77/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.4332\n",
            "Epoch 78/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 14.4192\n",
            "Epoch 79/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 14.4052\n",
            "Epoch 80/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.3912\n",
            "Epoch 81/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.3772\n",
            "Epoch 82/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.3632\n",
            "Epoch 83/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 14.3492\n",
            "Epoch 84/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 14.3352\n",
            "Epoch 85/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.3212\n",
            "Epoch 86/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 14.3072\n",
            "Epoch 87/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 14.2932\n",
            "Epoch 88/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.2793\n",
            "Epoch 89/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.2653\n",
            "Epoch 90/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 14.2513\n",
            "Epoch 91/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.2373\n",
            "Epoch 92/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.2233\n",
            "Epoch 93/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.2093\n",
            "Epoch 94/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.1953\n",
            "Epoch 95/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 14.1813\n",
            "Epoch 96/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 14.1673\n",
            "Epoch 97/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 14.1533\n",
            "Epoch 98/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.1393\n",
            "Epoch 99/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.1253\n",
            "Epoch 100/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 14.1113\n",
            "Epoch 101/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.0974\n",
            "Epoch 102/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.0834\n",
            "Epoch 103/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.0694\n",
            "Epoch 104/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 14.0554\n",
            "Epoch 105/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 14.0414\n",
            "Epoch 106/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 14.0274\n",
            "Epoch 107/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 14.0134\n",
            "Epoch 108/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.9994\n",
            "Epoch 109/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.9854\n",
            "Epoch 110/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 13.9714\n",
            "Epoch 111/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 13.9574\n",
            "Epoch 112/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.9434\n",
            "Epoch 113/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.9294\n",
            "Epoch 114/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 13.9155\n",
            "Epoch 115/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 13.9015\n",
            "Epoch 116/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 13.8875\n",
            "Epoch 117/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.8735\n",
            "Epoch 118/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 13.8595\n",
            "Epoch 119/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.8455\n",
            "Epoch 120/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.8315\n",
            "Epoch 121/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.8175\n",
            "Epoch 122/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.8035\n",
            "Epoch 123/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 13.7895\n",
            "Epoch 124/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.7755\n",
            "Epoch 125/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 13.7615\n",
            "Epoch 126/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.7475\n",
            "Epoch 127/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.7336\n",
            "Epoch 128/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.7196\n",
            "Epoch 129/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.7056\n",
            "Epoch 130/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.6916\n",
            "Epoch 131/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.6776\n",
            "Epoch 132/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.6636\n",
            "Epoch 133/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.6496\n",
            "Epoch 134/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.6356\n",
            "Epoch 135/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.6216\n",
            "Epoch 136/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.6076\n",
            "Epoch 137/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 13.5936\n",
            "Epoch 138/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.5796\n",
            "Epoch 139/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 13.5656\n",
            "Epoch 140/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.5517\n",
            "Epoch 141/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.5377\n",
            "Epoch 142/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.5237\n",
            "Epoch 143/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.5097\n",
            "Epoch 144/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.4957\n",
            "Epoch 145/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.4817\n",
            "Epoch 146/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.4677\n",
            "Epoch 147/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 13.4537\n",
            "Epoch 148/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.4397\n",
            "Epoch 149/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.4257\n",
            "Epoch 150/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.4117\n",
            "Epoch 151/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 13.3977\n",
            "Epoch 152/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 13.3837\n",
            "Epoch 153/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.3698\n",
            "Epoch 154/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.3558\n",
            "Epoch 155/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.3418\n",
            "Epoch 156/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.3278\n",
            "Epoch 157/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 13.3138\n",
            "Epoch 158/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.2998\n",
            "Epoch 159/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 13.2858\n",
            "Epoch 160/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 13.2718\n",
            "Epoch 161/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.2578\n",
            "Epoch 162/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 13.2438\n",
            "Epoch 163/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.2298\n",
            "Epoch 164/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.2158\n",
            "Epoch 165/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.2018\n",
            "Epoch 166/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.1879\n",
            "Epoch 167/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 13.1739\n",
            "Epoch 168/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 13.1599\n",
            "Epoch 169/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 13.1459\n",
            "Epoch 170/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 13.1319\n",
            "Epoch 171/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 13.1179\n",
            "Epoch 172/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 13.1039\n",
            "Epoch 173/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 13.0899\n",
            "Epoch 174/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 13.0759\n",
            "Epoch 175/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 13.0619\n",
            "Epoch 176/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 13.0479\n",
            "Epoch 177/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 13.0339\n",
            "Epoch 178/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 13.0199\n",
            "Epoch 179/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 13.0060\n",
            "Epoch 180/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.9920\n",
            "Epoch 181/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.9780\n",
            "Epoch 182/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.9640\n",
            "Epoch 183/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.9500\n",
            "Epoch 184/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.9360\n",
            "Epoch 185/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 12.9220\n",
            "Epoch 186/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.9080\n",
            "Epoch 187/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.8940\n",
            "Epoch 188/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.8800\n",
            "Epoch 189/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 12.8660\n",
            "Epoch 190/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 12.8520\n",
            "Epoch 191/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 12.8380\n",
            "Epoch 192/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.8241\n",
            "Epoch 193/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 12.8101\n",
            "Epoch 194/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 12.7961\n",
            "Epoch 195/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 12.7821\n",
            "Epoch 196/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 12.7681\n",
            "Epoch 197/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.7541\n",
            "Epoch 198/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 12.7401\n",
            "Epoch 199/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 12.7261\n",
            "Epoch 200/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.7121\n",
            "Epoch 201/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 12.6981\n",
            "Epoch 202/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.6841\n",
            "Epoch 203/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 12.6701\n",
            "Epoch 204/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 12.6561\n",
            "Epoch 205/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.6422\n",
            "Epoch 206/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 12.6282\n",
            "Epoch 207/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 12.6142\n",
            "Epoch 208/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 12.6002\n",
            "Epoch 209/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 12.5862\n",
            "Epoch 210/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.5722\n",
            "Epoch 211/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.5582\n",
            "Epoch 212/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 12.5442\n",
            "Epoch 213/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.5302\n",
            "Epoch 214/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 12.5162\n",
            "Epoch 215/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 12.5022\n",
            "Epoch 216/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 12.4882\n",
            "Epoch 217/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 12.4742\n",
            "Epoch 218/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.4603\n",
            "Epoch 219/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.4463\n",
            "Epoch 220/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.4323\n",
            "Epoch 221/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.4183\n",
            "Epoch 222/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.4043\n",
            "Epoch 223/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.3903\n",
            "Epoch 224/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 12.3763\n",
            "Epoch 225/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 12.3623\n",
            "Epoch 226/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.3483\n",
            "Epoch 227/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.3343\n",
            "Epoch 228/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 12.3203\n",
            "Epoch 229/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.3063\n",
            "Epoch 230/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.2923\n",
            "Epoch 231/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 12.2784\n",
            "Epoch 232/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.2644\n",
            "Epoch 233/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 12.2504\n",
            "Epoch 234/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.2364\n",
            "Epoch 235/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.2224\n",
            "Epoch 236/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 12.2084\n",
            "Epoch 237/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 12.1944\n",
            "Epoch 238/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.1804\n",
            "Epoch 239/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.1664\n",
            "Epoch 240/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.1524\n",
            "Epoch 241/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 12.1384\n",
            "Epoch 242/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.1244\n",
            "Epoch 243/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 12.1104\n",
            "Epoch 244/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 12.0965\n",
            "Epoch 245/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 12.0825\n",
            "Epoch 246/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 12.0685\n",
            "Epoch 247/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.0545\n",
            "Epoch 248/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 12.0405\n",
            "Epoch 249/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 12.0265\n",
            "Epoch 250/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 12.0125\n",
            "Epoch 251/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.9985\n",
            "Epoch 252/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.9845\n",
            "Epoch 253/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.9705\n",
            "Epoch 254/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.9565\n",
            "Epoch 255/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 11.9425\n",
            "Epoch 256/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 11.9285\n",
            "Epoch 257/1000\n",
            "873/873 [==============================] - 0s 44us/sample - loss: 11.9146\n",
            "Epoch 258/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 11.9006\n",
            "Epoch 259/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 11.8866\n",
            "Epoch 260/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 11.8726\n",
            "Epoch 261/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 11.8586\n",
            "Epoch 262/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.8446\n",
            "Epoch 263/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.8306\n",
            "Epoch 264/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.8166\n",
            "Epoch 265/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.8026\n",
            "Epoch 266/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.7886\n",
            "Epoch 267/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.7746\n",
            "Epoch 268/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 11.7606\n",
            "Epoch 269/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 11.7466\n",
            "Epoch 270/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.7327\n",
            "Epoch 271/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.7187\n",
            "Epoch 272/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.7047\n",
            "Epoch 273/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.6907\n",
            "Epoch 274/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 11.6767\n",
            "Epoch 275/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.6627\n",
            "Epoch 276/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 11.6487\n",
            "Epoch 277/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.6347\n",
            "Epoch 278/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.6207\n",
            "Epoch 279/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 11.6067\n",
            "Epoch 280/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 11.5927\n",
            "Epoch 281/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.5787\n",
            "Epoch 282/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.5647\n",
            "Epoch 283/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.5508\n",
            "Epoch 284/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 11.5368\n",
            "Epoch 285/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.5228\n",
            "Epoch 286/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.5088\n",
            "Epoch 287/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.4948\n",
            "Epoch 288/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.4808\n",
            "Epoch 289/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.4668\n",
            "Epoch 290/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.4528\n",
            "Epoch 291/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.4388\n",
            "Epoch 292/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 11.4248\n",
            "Epoch 293/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.4108\n",
            "Epoch 294/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.3968\n",
            "Epoch 295/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.3828\n",
            "Epoch 296/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.3689\n",
            "Epoch 297/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.3549\n",
            "Epoch 298/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.3409\n",
            "Epoch 299/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 11.3269\n",
            "Epoch 300/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 11.3129\n",
            "Epoch 301/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 11.2989\n",
            "Epoch 302/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.2849\n",
            "Epoch 303/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.2709\n",
            "Epoch 304/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.2569\n",
            "Epoch 305/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.2429\n",
            "Epoch 306/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 11.2289\n",
            "Epoch 307/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.2149\n",
            "Epoch 308/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 11.2009\n",
            "Epoch 309/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.1870\n",
            "Epoch 310/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.1730\n",
            "Epoch 311/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 11.1590\n",
            "Epoch 312/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.1450\n",
            "Epoch 313/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 11.1310\n",
            "Epoch 314/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 11.1170\n",
            "Epoch 315/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.1030\n",
            "Epoch 316/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.0890\n",
            "Epoch 317/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.0750\n",
            "Epoch 318/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 11.0610\n",
            "Epoch 319/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.0470\n",
            "Epoch 320/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 11.0330\n",
            "Epoch 321/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 11.0190\n",
            "Epoch 322/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 11.0051\n",
            "Epoch 323/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 10.9911\n",
            "Epoch 324/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 10.9771\n",
            "Epoch 325/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 10.9631\n",
            "Epoch 326/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 10.9491\n",
            "Epoch 327/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.9351\n",
            "Epoch 328/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.9211\n",
            "Epoch 329/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 10.9071\n",
            "Epoch 330/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 10.8931\n",
            "Epoch 331/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 10.8791\n",
            "Epoch 332/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 10.8651\n",
            "Epoch 333/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.8511\n",
            "Epoch 334/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.8371\n",
            "Epoch 335/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.8232\n",
            "Epoch 336/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.8092\n",
            "Epoch 337/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 10.7952\n",
            "Epoch 338/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.7812\n",
            "Epoch 339/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.7672\n",
            "Epoch 340/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 10.7532\n",
            "Epoch 341/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 10.7392\n",
            "Epoch 342/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.7252\n",
            "Epoch 343/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 10.7112\n",
            "Epoch 344/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.6972\n",
            "Epoch 345/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.6832\n",
            "Epoch 346/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 10.6692\n",
            "Epoch 347/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.6552\n",
            "Epoch 348/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.6413\n",
            "Epoch 349/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.6273\n",
            "Epoch 350/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 10.6133\n",
            "Epoch 351/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 10.5993\n",
            "Epoch 352/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.5853\n",
            "Epoch 353/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.5713\n",
            "Epoch 354/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 10.5573\n",
            "Epoch 355/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 10.5433\n",
            "Epoch 356/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.5293\n",
            "Epoch 357/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.5153\n",
            "Epoch 358/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.5013\n",
            "Epoch 359/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 10.4873\n",
            "Epoch 360/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.4733\n",
            "Epoch 361/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.4594\n",
            "Epoch 362/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 10.4454\n",
            "Epoch 363/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.4314\n",
            "Epoch 364/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.4174\n",
            "Epoch 365/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 10.4034\n",
            "Epoch 366/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.3894\n",
            "Epoch 367/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.3754\n",
            "Epoch 368/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.3614\n",
            "Epoch 369/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.3474\n",
            "Epoch 370/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.3334\n",
            "Epoch 371/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.3194\n",
            "Epoch 372/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.3054\n",
            "Epoch 373/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.2914\n",
            "Epoch 374/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 10.2775\n",
            "Epoch 375/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.2635\n",
            "Epoch 376/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 10.2495\n",
            "Epoch 377/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.2355\n",
            "Epoch 378/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 10.2215\n",
            "Epoch 379/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 10.2075\n",
            "Epoch 380/1000\n",
            "873/873 [==============================] - 0s 43us/sample - loss: 10.1935\n",
            "Epoch 381/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.1795\n",
            "Epoch 382/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 10.1655\n",
            "Epoch 383/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.1515\n",
            "Epoch 384/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 10.1375\n",
            "Epoch 385/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.1235\n",
            "Epoch 386/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 10.1095\n",
            "Epoch 387/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 10.0956\n",
            "Epoch 388/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 10.0816\n",
            "Epoch 389/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 10.0676\n",
            "Epoch 390/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.0536\n",
            "Epoch 391/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.0396\n",
            "Epoch 392/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 10.0256\n",
            "Epoch 393/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 10.0116\n",
            "Epoch 394/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.9976\n",
            "Epoch 395/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.9836\n",
            "Epoch 396/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.9696\n",
            "Epoch 397/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.9556\n",
            "Epoch 398/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.9416\n",
            "Epoch 399/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.9276\n",
            "Epoch 400/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 9.9137\n",
            "Epoch 401/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 9.8997\n",
            "Epoch 402/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.8857\n",
            "Epoch 403/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.8717\n",
            "Epoch 404/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 9.8577\n",
            "Epoch 405/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.8437\n",
            "Epoch 406/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.8297\n",
            "Epoch 407/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 9.8157\n",
            "Epoch 408/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 9.8017\n",
            "Epoch 409/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 9.7877\n",
            "Epoch 410/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.7737\n",
            "Epoch 411/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.7597\n",
            "Epoch 412/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.7457\n",
            "Epoch 413/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 9.7318\n",
            "Epoch 414/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 9.7178\n",
            "Epoch 415/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.7038\n",
            "Epoch 416/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 9.6898\n",
            "Epoch 417/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.6758\n",
            "Epoch 418/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.6618\n",
            "Epoch 419/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 9.6478\n",
            "Epoch 420/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 9.6338\n",
            "Epoch 421/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.6198\n",
            "Epoch 422/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 9.6058\n",
            "Epoch 423/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 9.5918\n",
            "Epoch 424/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.5778\n",
            "Epoch 425/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 9.5638\n",
            "Epoch 426/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.5499\n",
            "Epoch 427/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.5359\n",
            "Epoch 428/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 9.5219\n",
            "Epoch 429/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.5079\n",
            "Epoch 430/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.4939\n",
            "Epoch 431/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 9.4799\n",
            "Epoch 432/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.4659\n",
            "Epoch 433/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.4519\n",
            "Epoch 434/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 9.4379\n",
            "Epoch 435/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.4239\n",
            "Epoch 436/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 9.4099\n",
            "Epoch 437/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.3959\n",
            "Epoch 438/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.3819\n",
            "Epoch 439/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 9.3680\n",
            "Epoch 440/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 9.3540\n",
            "Epoch 441/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 9.3400\n",
            "Epoch 442/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.3260\n",
            "Epoch 443/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.3120\n",
            "Epoch 444/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 9.2980\n",
            "Epoch 445/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 9.2840\n",
            "Epoch 446/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.2700\n",
            "Epoch 447/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.2560\n",
            "Epoch 448/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 9.2420\n",
            "Epoch 449/1000\n",
            "873/873 [==============================] - 0s 43us/sample - loss: 9.2280\n",
            "Epoch 450/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 9.2140\n",
            "Epoch 451/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 9.2000\n",
            "Epoch 452/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.1861\n",
            "Epoch 453/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 9.1721\n",
            "Epoch 454/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 9.1581\n",
            "Epoch 455/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 9.1441\n",
            "Epoch 456/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 9.1301\n",
            "Epoch 457/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.1161\n",
            "Epoch 458/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.1021\n",
            "Epoch 459/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.0881\n",
            "Epoch 460/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.0741\n",
            "Epoch 461/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 9.0601\n",
            "Epoch 462/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 9.0461\n",
            "Epoch 463/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 9.0321\n",
            "Epoch 464/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 9.0181\n",
            "Epoch 465/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 9.0042\n",
            "Epoch 466/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.9902\n",
            "Epoch 467/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 8.9762\n",
            "Epoch 468/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.9622\n",
            "Epoch 469/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 8.9482\n",
            "Epoch 470/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.9342\n",
            "Epoch 471/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 8.9202\n",
            "Epoch 472/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 8.9062\n",
            "Epoch 473/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.8922\n",
            "Epoch 474/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 8.8782\n",
            "Epoch 475/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 8.8642\n",
            "Epoch 476/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.8502\n",
            "Epoch 477/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.8362\n",
            "Epoch 478/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 8.8223\n",
            "Epoch 479/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.8083\n",
            "Epoch 480/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.7943\n",
            "Epoch 481/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 8.7803\n",
            "Epoch 482/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 8.7663\n",
            "Epoch 483/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 8.7523\n",
            "Epoch 484/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.7383\n",
            "Epoch 485/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.7243\n",
            "Epoch 486/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.7103\n",
            "Epoch 487/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.6963\n",
            "Epoch 488/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.6823\n",
            "Epoch 489/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.6683\n",
            "Epoch 490/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 8.6543\n",
            "Epoch 491/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 8.6404\n",
            "Epoch 492/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 8.6264\n",
            "Epoch 493/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.6124\n",
            "Epoch 494/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.5984\n",
            "Epoch 495/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.5844\n",
            "Epoch 496/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.5704\n",
            "Epoch 497/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.5564\n",
            "Epoch 498/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 8.5424\n",
            "Epoch 499/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 8.5284\n",
            "Epoch 500/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 8.5144\n",
            "Epoch 501/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 8.5004\n",
            "Epoch 502/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 8.4864\n",
            "Epoch 503/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.4724\n",
            "Epoch 504/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 8.4585\n",
            "Epoch 505/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 8.4445\n",
            "Epoch 506/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.4305\n",
            "Epoch 507/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.4165\n",
            "Epoch 508/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 8.4025\n",
            "Epoch 509/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 8.3885\n",
            "Epoch 510/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 8.3745\n",
            "Epoch 511/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.3605\n",
            "Epoch 512/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 8.3465\n",
            "Epoch 513/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.3325\n",
            "Epoch 514/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 8.3185\n",
            "Epoch 515/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 8.3045\n",
            "Epoch 516/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 8.2905\n",
            "Epoch 517/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 8.2766\n",
            "Epoch 518/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.2626\n",
            "Epoch 519/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 8.2486\n",
            "Epoch 520/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 8.2346\n",
            "Epoch 521/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 8.2206\n",
            "Epoch 522/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.2066\n",
            "Epoch 523/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 8.1926\n",
            "Epoch 524/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 8.1786\n",
            "Epoch 525/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 8.1646\n",
            "Epoch 526/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 8.1506\n",
            "Epoch 527/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 8.1366\n",
            "Epoch 528/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 8.1226\n",
            "Epoch 529/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 8.1086\n",
            "Epoch 530/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 8.0947\n",
            "Epoch 531/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 8.0807\n",
            "Epoch 532/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 8.0667\n",
            "Epoch 533/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 8.0527\n",
            "Epoch 534/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 8.0387\n",
            "Epoch 535/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 8.0247\n",
            "Epoch 536/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 8.0107\n",
            "Epoch 537/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.9967\n",
            "Epoch 538/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.9827\n",
            "Epoch 539/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.9687\n",
            "Epoch 540/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.9547\n",
            "Epoch 541/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.9407\n",
            "Epoch 542/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 7.9267\n",
            "Epoch 543/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 7.9128\n",
            "Epoch 544/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.8988\n",
            "Epoch 545/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 7.8848\n",
            "Epoch 546/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.8708\n",
            "Epoch 547/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 7.8568\n",
            "Epoch 548/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.8428\n",
            "Epoch 549/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.8288\n",
            "Epoch 550/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.8148\n",
            "Epoch 551/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 7.8008\n",
            "Epoch 552/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.7868\n",
            "Epoch 553/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.7728\n",
            "Epoch 554/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 7.7588\n",
            "Epoch 555/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.7448\n",
            "Epoch 556/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.7309\n",
            "Epoch 557/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.7169\n",
            "Epoch 558/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.7029\n",
            "Epoch 559/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.6889\n",
            "Epoch 560/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.6749\n",
            "Epoch 561/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.6609\n",
            "Epoch 562/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.6469\n",
            "Epoch 563/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 7.6329\n",
            "Epoch 564/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.6189\n",
            "Epoch 565/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.6049\n",
            "Epoch 566/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.5909\n",
            "Epoch 567/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 7.5769\n",
            "Epoch 568/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.5629\n",
            "Epoch 569/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.5490\n",
            "Epoch 570/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.5350\n",
            "Epoch 571/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.5210\n",
            "Epoch 572/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.5070\n",
            "Epoch 573/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 7.4929\n",
            "Epoch 574/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.4789\n",
            "Epoch 575/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.4649\n",
            "Epoch 576/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.4509\n",
            "Epoch 577/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.4369\n",
            "Epoch 578/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.4229\n",
            "Epoch 579/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.4089\n",
            "Epoch 580/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.3949\n",
            "Epoch 581/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.3809\n",
            "Epoch 582/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.3669\n",
            "Epoch 583/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.3529\n",
            "Epoch 584/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 7.3389\n",
            "Epoch 585/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 7.3249\n",
            "Epoch 586/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 7.3109\n",
            "Epoch 587/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 7.2969\n",
            "Epoch 588/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 7.2829\n",
            "Epoch 589/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.2689\n",
            "Epoch 590/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 7.2549\n",
            "Epoch 591/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 7.2408\n",
            "Epoch 592/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 7.2268\n",
            "Epoch 593/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 7.2128\n",
            "Epoch 594/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.1988\n",
            "Epoch 595/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.1848\n",
            "Epoch 596/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.1708\n",
            "Epoch 597/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.1568\n",
            "Epoch 598/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.1428\n",
            "Epoch 599/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.1288\n",
            "Epoch 600/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.1148\n",
            "Epoch 601/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.1008\n",
            "Epoch 602/1000\n",
            "873/873 [==============================] - 0s 28us/sample - loss: 7.0868\n",
            "Epoch 603/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.0728\n",
            "Epoch 604/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 7.0588\n",
            "Epoch 605/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 7.0448\n",
            "Epoch 606/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 7.0308\n",
            "Epoch 607/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 7.0168\n",
            "Epoch 608/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 7.0028\n",
            "Epoch 609/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.9887\n",
            "Epoch 610/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.9747\n",
            "Epoch 611/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.9607\n",
            "Epoch 612/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 6.9467\n",
            "Epoch 613/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 6.9327\n",
            "Epoch 614/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 6.9187\n",
            "Epoch 615/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 6.9047\n",
            "Epoch 616/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.8907\n",
            "Epoch 617/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.8767\n",
            "Epoch 618/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 6.8627\n",
            "Epoch 619/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 6.8487\n",
            "Epoch 620/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.8347\n",
            "Epoch 621/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.8207\n",
            "Epoch 622/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.8067\n",
            "Epoch 623/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.7927\n",
            "Epoch 624/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.7787\n",
            "Epoch 625/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.7647\n",
            "Epoch 626/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.7506\n",
            "Epoch 627/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.7366\n",
            "Epoch 628/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.7226\n",
            "Epoch 629/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.7086\n",
            "Epoch 630/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.6946\n",
            "Epoch 631/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.6806\n",
            "Epoch 632/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 6.6666\n",
            "Epoch 633/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.6526\n",
            "Epoch 634/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.6386\n",
            "Epoch 635/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 6.6246\n",
            "Epoch 636/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.6106\n",
            "Epoch 637/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.5966\n",
            "Epoch 638/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 6.5826\n",
            "Epoch 639/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 6.5686\n",
            "Epoch 640/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.5546\n",
            "Epoch 641/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.5406\n",
            "Epoch 642/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 6.5266\n",
            "Epoch 643/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.5126\n",
            "Epoch 644/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.4985\n",
            "Epoch 645/1000\n",
            "873/873 [==============================] - 0s 29us/sample - loss: 6.4845\n",
            "Epoch 646/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.4705\n",
            "Epoch 647/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.4565\n",
            "Epoch 648/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.4425\n",
            "Epoch 649/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.4285\n",
            "Epoch 650/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.4145\n",
            "Epoch 651/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 6.4005\n",
            "Epoch 652/1000\n",
            "873/873 [==============================] - 0s 30us/sample - loss: 6.3865\n",
            "Epoch 653/1000\n",
            "873/873 [==============================] - 0s 45us/sample - loss: 6.3725\n",
            "Epoch 654/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.3585\n",
            "Epoch 655/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.3445\n",
            "Epoch 656/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.3305\n",
            "Epoch 657/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.3165\n",
            "Epoch 658/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.3025\n",
            "Epoch 659/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.2885\n",
            "Epoch 660/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.2745\n",
            "Epoch 661/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 6.2605\n",
            "Epoch 662/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 6.2464\n",
            "Epoch 663/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.2324\n",
            "Epoch 664/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.2184\n",
            "Epoch 665/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.2044\n",
            "Epoch 666/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 6.1904\n",
            "Epoch 667/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 6.1764\n",
            "Epoch 668/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 6.1624\n",
            "Epoch 669/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.1484\n",
            "Epoch 670/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.1344\n",
            "Epoch 671/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 6.1204\n",
            "Epoch 672/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.1064\n",
            "Epoch 673/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 6.0924\n",
            "Epoch 674/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 6.0784\n",
            "Epoch 675/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 6.0644\n",
            "Epoch 676/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 6.0504\n",
            "Epoch 677/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 6.0364\n",
            "Epoch 678/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 6.0224\n",
            "Epoch 679/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 6.0083\n",
            "Epoch 680/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 5.9943\n",
            "Epoch 681/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 5.9803\n",
            "Epoch 682/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 5.9663\n",
            "Epoch 683/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 5.9523\n",
            "Epoch 684/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 5.9383\n",
            "Epoch 685/1000\n",
            "873/873 [==============================] - 0s 47us/sample - loss: 5.9243\n",
            "Epoch 686/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.9103\n",
            "Epoch 687/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 5.8963\n",
            "Epoch 688/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.8823\n",
            "Epoch 689/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 5.8683\n",
            "Epoch 690/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 5.8543\n",
            "Epoch 691/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 5.8403\n",
            "Epoch 692/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 5.8263\n",
            "Epoch 693/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.8123\n",
            "Epoch 694/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 5.7983\n",
            "Epoch 695/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 5.7843\n",
            "Epoch 696/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 5.7703\n",
            "Epoch 697/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.7562\n",
            "Epoch 698/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 5.7422\n",
            "Epoch 699/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 5.7282\n",
            "Epoch 700/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 5.7142\n",
            "Epoch 701/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 5.7002\n",
            "Epoch 702/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 5.6862\n",
            "Epoch 703/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 5.6722\n",
            "Epoch 704/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.6582\n",
            "Epoch 705/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.6442\n",
            "Epoch 706/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 5.6302\n",
            "Epoch 707/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.6162\n",
            "Epoch 708/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 5.6022\n",
            "Epoch 709/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 5.5882\n",
            "Epoch 710/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 5.5742\n",
            "Epoch 711/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.5602\n",
            "Epoch 712/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.5462\n",
            "Epoch 713/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.5322\n",
            "Epoch 714/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 5.5182\n",
            "Epoch 715/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 5.5041\n",
            "Epoch 716/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 5.4901\n",
            "Epoch 717/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 5.4761\n",
            "Epoch 718/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 5.4621\n",
            "Epoch 719/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.4481\n",
            "Epoch 720/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.4341\n",
            "Epoch 721/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 5.4201\n",
            "Epoch 722/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 5.4061\n",
            "Epoch 723/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 5.3921\n",
            "Epoch 724/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 5.3781\n",
            "Epoch 725/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.3641\n",
            "Epoch 726/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.3501\n",
            "Epoch 727/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 5.3361\n",
            "Epoch 728/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.3221\n",
            "Epoch 729/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.3081\n",
            "Epoch 730/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.2941\n",
            "Epoch 731/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 5.2801\n",
            "Epoch 732/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.2660\n",
            "Epoch 733/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.2520\n",
            "Epoch 734/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.2380\n",
            "Epoch 735/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 5.2240\n",
            "Epoch 736/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 5.2100\n",
            "Epoch 737/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.1960\n",
            "Epoch 738/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.1820\n",
            "Epoch 739/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 5.1680\n",
            "Epoch 740/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.1540\n",
            "Epoch 741/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.1400\n",
            "Epoch 742/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.1260\n",
            "Epoch 743/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.1120\n",
            "Epoch 744/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 5.0980\n",
            "Epoch 745/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.0840\n",
            "Epoch 746/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.0700\n",
            "Epoch 747/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 5.0560\n",
            "Epoch 748/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 5.0420\n",
            "Epoch 749/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 5.0280\n",
            "Epoch 750/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 5.0139\n",
            "Epoch 751/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 4.9999\n",
            "Epoch 752/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.9859\n",
            "Epoch 753/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 4.9719\n",
            "Epoch 754/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.9579\n",
            "Epoch 755/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 4.9439\n",
            "Epoch 756/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.9299\n",
            "Epoch 757/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.9159\n",
            "Epoch 758/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.9019\n",
            "Epoch 759/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.8879\n",
            "Epoch 760/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.8739\n",
            "Epoch 761/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 4.8599\n",
            "Epoch 762/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.8459\n",
            "Epoch 763/1000\n",
            "873/873 [==============================] - 0s 45us/sample - loss: 4.8319\n",
            "Epoch 764/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 4.8179\n",
            "Epoch 765/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.8039\n",
            "Epoch 766/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 4.7899\n",
            "Epoch 767/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.7759\n",
            "Epoch 768/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.7618\n",
            "Epoch 769/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 4.7478\n",
            "Epoch 770/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.7338\n",
            "Epoch 771/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.7198\n",
            "Epoch 772/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.7058\n",
            "Epoch 773/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.6918\n",
            "Epoch 774/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 4.6778\n",
            "Epoch 775/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.6638\n",
            "Epoch 776/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.6498\n",
            "Epoch 777/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 4.6358\n",
            "Epoch 778/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.6218\n",
            "Epoch 779/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.6078\n",
            "Epoch 780/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.5938\n",
            "Epoch 781/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.5798\n",
            "Epoch 782/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 4.5658\n",
            "Epoch 783/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.5518\n",
            "Epoch 784/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.5378\n",
            "Epoch 785/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.5237\n",
            "Epoch 786/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.5097\n",
            "Epoch 787/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.4957\n",
            "Epoch 788/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.4817\n",
            "Epoch 789/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.4677\n",
            "Epoch 790/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 4.4537\n",
            "Epoch 791/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 4.4397\n",
            "Epoch 792/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.4257\n",
            "Epoch 793/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.4117\n",
            "Epoch 794/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.3977\n",
            "Epoch 795/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 4.3837\n",
            "Epoch 796/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 4.3697\n",
            "Epoch 797/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 4.3557\n",
            "Epoch 798/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.3417\n",
            "Epoch 799/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 4.3277\n",
            "Epoch 800/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.3137\n",
            "Epoch 801/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.2997\n",
            "Epoch 802/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 4.2857\n",
            "Epoch 803/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.2716\n",
            "Epoch 804/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.2576\n",
            "Epoch 805/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.2436\n",
            "Epoch 806/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.2296\n",
            "Epoch 807/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 4.2156\n",
            "Epoch 808/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.2016\n",
            "Epoch 809/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.1876\n",
            "Epoch 810/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 4.1736\n",
            "Epoch 811/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.1596\n",
            "Epoch 812/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 4.1456\n",
            "Epoch 813/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.1316\n",
            "Epoch 814/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 4.1176\n",
            "Epoch 815/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.1036\n",
            "Epoch 816/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 4.0896\n",
            "Epoch 817/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 4.0756\n",
            "Epoch 818/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 4.0616\n",
            "Epoch 819/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.0476\n",
            "Epoch 820/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 4.0336\n",
            "Epoch 821/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.0195\n",
            "Epoch 822/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 4.0055\n",
            "Epoch 823/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.9915\n",
            "Epoch 824/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.9775\n",
            "Epoch 825/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.9635\n",
            "Epoch 826/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.9495\n",
            "Epoch 827/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.9355\n",
            "Epoch 828/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.9215\n",
            "Epoch 829/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.9075\n",
            "Epoch 830/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.8935\n",
            "Epoch 831/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.8795\n",
            "Epoch 832/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.8655\n",
            "Epoch 833/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.8515\n",
            "Epoch 834/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.8375\n",
            "Epoch 835/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.8235\n",
            "Epoch 836/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.8095\n",
            "Epoch 837/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 3.7955\n",
            "Epoch 838/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 3.7814\n",
            "Epoch 839/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 3.7674\n",
            "Epoch 840/1000\n",
            "873/873 [==============================] - 0s 43us/sample - loss: 3.7534\n",
            "Epoch 841/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.7394\n",
            "Epoch 842/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.7254\n",
            "Epoch 843/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.7114\n",
            "Epoch 844/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.6974\n",
            "Epoch 845/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 3.6834\n",
            "Epoch 846/1000\n",
            "873/873 [==============================] - 0s 47us/sample - loss: 3.6694\n",
            "Epoch 847/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.6554\n",
            "Epoch 848/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.6414\n",
            "Epoch 849/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 3.6274\n",
            "Epoch 850/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.6134\n",
            "Epoch 851/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 3.5994\n",
            "Epoch 852/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 3.5854\n",
            "Epoch 853/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.5714\n",
            "Epoch 854/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 3.5574\n",
            "Epoch 855/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.5434\n",
            "Epoch 856/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.5293\n",
            "Epoch 857/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.5153\n",
            "Epoch 858/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.5014\n",
            "Epoch 859/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.4874\n",
            "Epoch 860/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.4734\n",
            "Epoch 861/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 3.4594\n",
            "Epoch 862/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.4454\n",
            "Epoch 863/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.4314\n",
            "Epoch 864/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.4174\n",
            "Epoch 865/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 3.4034\n",
            "Epoch 866/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 3.3894\n",
            "Epoch 867/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.3754\n",
            "Epoch 868/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.3614\n",
            "Epoch 869/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.3474\n",
            "Epoch 870/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.3334\n",
            "Epoch 871/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 3.3194\n",
            "Epoch 872/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.3054\n",
            "Epoch 873/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.2914\n",
            "Epoch 874/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.2774\n",
            "Epoch 875/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 3.2634\n",
            "Epoch 876/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.2494\n",
            "Epoch 877/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 3.2354\n",
            "Epoch 878/1000\n",
            "873/873 [==============================] - 0s 42us/sample - loss: 3.2214\n",
            "Epoch 879/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.2074\n",
            "Epoch 880/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.1934\n",
            "Epoch 881/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 3.1794\n",
            "Epoch 882/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 3.1654\n",
            "Epoch 883/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 3.1514\n",
            "Epoch 884/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.1374\n",
            "Epoch 885/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 3.1234\n",
            "Epoch 886/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 3.1094\n",
            "Epoch 887/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 3.0954\n",
            "Epoch 888/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.0814\n",
            "Epoch 889/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.0674\n",
            "Epoch 890/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.0534\n",
            "Epoch 891/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 3.0394\n",
            "Epoch 892/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 3.0254\n",
            "Epoch 893/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 3.0114\n",
            "Epoch 894/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.9974\n",
            "Epoch 895/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.9834\n",
            "Epoch 896/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.9694\n",
            "Epoch 897/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 2.9554\n",
            "Epoch 898/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 2.9414\n",
            "Epoch 899/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 2.9274\n",
            "Epoch 900/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.9134\n",
            "Epoch 901/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.8994\n",
            "Epoch 902/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.8854\n",
            "Epoch 903/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.8714\n",
            "Epoch 904/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 2.8574\n",
            "Epoch 905/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.8434\n",
            "Epoch 906/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.8294\n",
            "Epoch 907/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 2.8154\n",
            "Epoch 908/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.8014\n",
            "Epoch 909/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 2.7874\n",
            "Epoch 910/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.7734\n",
            "Epoch 911/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.7594\n",
            "Epoch 912/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 2.7454\n",
            "Epoch 913/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.7314\n",
            "Epoch 914/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.7174\n",
            "Epoch 915/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.7034\n",
            "Epoch 916/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.6894\n",
            "Epoch 917/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 2.6754\n",
            "Epoch 918/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 2.6614\n",
            "Epoch 919/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 2.6474\n",
            "Epoch 920/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 2.6334\n",
            "Epoch 921/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.6194\n",
            "Epoch 922/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 2.6054\n",
            "Epoch 923/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.5914\n",
            "Epoch 924/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.5774\n",
            "Epoch 925/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.5634\n",
            "Epoch 926/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.5494\n",
            "Epoch 927/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.5354\n",
            "Epoch 928/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 2.5214\n",
            "Epoch 929/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.5074\n",
            "Epoch 930/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 2.4934\n",
            "Epoch 931/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.4794\n",
            "Epoch 932/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 2.4654\n",
            "Epoch 933/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.4514\n",
            "Epoch 934/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.4374\n",
            "Epoch 935/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 2.4234\n",
            "Epoch 936/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.4094\n",
            "Epoch 937/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.3954\n",
            "Epoch 938/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 2.3814\n",
            "Epoch 939/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.3674\n",
            "Epoch 940/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 2.3534\n",
            "Epoch 941/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 2.3394\n",
            "Epoch 942/1000\n",
            "873/873 [==============================] - 0s 45us/sample - loss: 2.3254\n",
            "Epoch 943/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.3114\n",
            "Epoch 944/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.2974\n",
            "Epoch 945/1000\n",
            "873/873 [==============================] - 0s 40us/sample - loss: 2.2834\n",
            "Epoch 946/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.2694\n",
            "Epoch 947/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 2.2554\n",
            "Epoch 948/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.2414\n",
            "Epoch 949/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 2.2274\n",
            "Epoch 950/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 2.2134\n",
            "Epoch 951/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 2.1994\n",
            "Epoch 952/1000\n",
            "873/873 [==============================] - 0s 39us/sample - loss: 2.1854\n",
            "Epoch 953/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.1714\n",
            "Epoch 954/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 2.1574\n",
            "Epoch 955/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.1434\n",
            "Epoch 956/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 2.1295\n",
            "Epoch 957/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 2.1155\n",
            "Epoch 958/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.1015\n",
            "Epoch 959/1000\n",
            "873/873 [==============================] - 0s 31us/sample - loss: 2.0875\n",
            "Epoch 960/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 2.0735\n",
            "Epoch 961/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 2.0595\n",
            "Epoch 962/1000\n",
            "873/873 [==============================] - 0s 47us/sample - loss: 2.0455\n",
            "Epoch 963/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 2.0315\n",
            "Epoch 964/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 2.0175\n",
            "Epoch 965/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 2.0035\n",
            "Epoch 966/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 1.9895\n",
            "Epoch 967/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.9755\n",
            "Epoch 968/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 1.9615\n",
            "Epoch 969/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 1.9475\n",
            "Epoch 970/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 1.9335\n",
            "Epoch 971/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.9195\n",
            "Epoch 972/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.9055\n",
            "Epoch 973/1000\n",
            "873/873 [==============================] - 0s 41us/sample - loss: 1.8915\n",
            "Epoch 974/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.8775\n",
            "Epoch 975/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 1.8635\n",
            "Epoch 976/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 1.8495\n",
            "Epoch 977/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.8355\n",
            "Epoch 978/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 1.8215\n",
            "Epoch 979/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 1.8075\n",
            "Epoch 980/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 1.7935\n",
            "Epoch 981/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 1.7795\n",
            "Epoch 982/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.7655\n",
            "Epoch 983/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.7515\n",
            "Epoch 984/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 1.7375\n",
            "Epoch 985/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 1.7235\n",
            "Epoch 986/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 1.7095\n",
            "Epoch 987/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.6955\n",
            "Epoch 988/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 1.6815\n",
            "Epoch 989/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 1.6675\n",
            "Epoch 990/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 1.6535\n",
            "Epoch 991/1000\n",
            "873/873 [==============================] - 0s 33us/sample - loss: 1.6395\n",
            "Epoch 992/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 1.6255\n",
            "Epoch 993/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 1.6115\n",
            "Epoch 994/1000\n",
            "873/873 [==============================] - 0s 35us/sample - loss: 1.5975\n",
            "Epoch 995/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 1.5835\n",
            "Epoch 996/1000\n",
            "873/873 [==============================] - 0s 37us/sample - loss: 1.5695\n",
            "Epoch 997/1000\n",
            "873/873 [==============================] - 0s 38us/sample - loss: 1.5555\n",
            "Epoch 998/1000\n",
            "873/873 [==============================] - 0s 32us/sample - loss: 1.5415\n",
            "Epoch 999/1000\n",
            "873/873 [==============================] - 0s 36us/sample - loss: 1.5275\n",
            "Epoch 1000/1000\n",
            "873/873 [==============================] - 0s 34us/sample - loss: 1.5135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHHj1SorV69g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7d9350cd-6730-44c5-d201-53b77cbd1870"
      },
      "source": [
        "Y_hat_h0_f = model.predict(X_test_h0_f)\n",
        "Y_hat_h0_f[:5]"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9739058],\n",
              "       [1.9739058],\n",
              "       [1.9739058],\n",
              "       [1.9739058],\n",
              "       [1.9739058]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqafMdscV609",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_hat_h0 = scaler_y.inverse_transform(Y_hat_h0_f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGNoKvvdX_fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c7cae05-bd1b-4309-e28f-d0fae360b467"
      },
      "source": [
        "Y_test_h0[:5]"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23642., 25135., 28425., 26986., 28284.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzhw0IYmX_cA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "639b46a3-ce01-43b0-82e5-53d9d20b299f"
      },
      "source": [
        "Y_hat_h0[:5]"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[41287.46],\n",
              "       [41287.46],\n",
              "       [41287.46],\n",
              "       [41287.46],\n",
              "       [41287.46]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkPEwjtsX_X6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-3ofwwQV6pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQCN6xPZhh7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_loss(history):\n",
        "  fig = plt.figure(figsize=(8,7))\n",
        "  lrs = 1e-8 *(10**(np.arange(100)/20))\n",
        "  plt.semilogx(lrs, history.history['loss'])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_QBOGSfURPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "6df3e0a4-e18b-4284-918c-c69144bda642"
      },
      "source": [
        "plot_loss(history)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAGjCAYAAAAfL31UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1ebfflpURBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu_LKQpY630y",
        "colab_type": "text"
      },
      "source": [
        "# Multivariate\n",
        "\n",
        "X is \n",
        "- 3 lag terms\n",
        "- 3 lag weather terms\n",
        "\n",
        "X \n",
        "- et-1 et-2 et-3\n",
        "- wt-1 wt-2 wt-3\n",
        "\n",
        "Y\n",
        "- t\n",
        "\n",
        "\n",
        "Constructing the X vector for input into a MLP\n",
        "\n",
        "Must input as the form:\n",
        "- et-1, wt-1, et-2, wt-2, et-3, wt-3\n",
        "\n",
        "To do this:\n",
        "1. For each feature take each row and reshape to (num_lags, 1)\n",
        "2. Append each reshaped row to a list. One list per feature.\n",
        "3. Concatenate the arrays together. Shape should be (number_samples, num_lags, num_features)\n",
        "4. Reshape to the form (number_samples, num_lags * num_features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3gEYu8e8C1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cef9e8e0-ea60-4dad-df5f-b990f3d69477"
      },
      "source": [
        "!ls -l short-term-energy-demand-forecasting/data/weather_2013_2019.csv"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 77316\n",
            "drwxr-xr-x 2 root root     4096 Aug 31 18:21 cleaned_data\n",
            "drwxr-xr-x 2 root root     4096 Aug 31 18:21 processed\n",
            "drwxr-xr-x 2 root root     4096 Aug 31 18:21 raw_data_ES\n",
            "-rw-r--r-- 1 root root 39576929 Aug 31 18:21 weather_2013_2019.csv\n",
            "-rw-r--r-- 1 root root 39576929 Aug 31 18:21 weeather_2013_2019.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1TmlfHJkr_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather = pd.read_csv('short-term-energy-demand-forecasting/data/weather_2013_2019.csv', parse_dates=True, index_col='dt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a_rWE318aay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "24b8f579-d2d4-43ce-b1e9-7bc20c05cd0f"
      },
      "source": [
        "weather.head(2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>dt_iso</th>\n",
              "      <th>city_id</th>\n",
              "      <th>city_name</th>\n",
              "      <th>temp</th>\n",
              "      <th>temp_min</th>\n",
              "      <th>temp_max</th>\n",
              "      <th>pressure</th>\n",
              "      <th>humidity</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_deg</th>\n",
              "      <th>rain_1h</th>\n",
              "      <th>rain_3h</th>\n",
              "      <th>snow_3h</th>\n",
              "      <th>clouds_all</th>\n",
              "      <th>weather_id</th>\n",
              "      <th>weather_main</th>\n",
              "      <th>weather_description</th>\n",
              "      <th>weather_icon</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-10-01 02:00:00</th>\n",
              "      <td>0</td>\n",
              "      <td>2013-10-01 00:00:00 +0000 UTC</td>\n",
              "      <td>2509954</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>299.15</td>\n",
              "      <td>299.15</td>\n",
              "      <td>299.15</td>\n",
              "      <td>1008</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>290</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20</td>\n",
              "      <td>801</td>\n",
              "      <td>clouds</td>\n",
              "      <td>few clouds</td>\n",
              "      <td>02n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-01 03:00:00</th>\n",
              "      <td>1</td>\n",
              "      <td>2013-10-01 01:00:00 +0000 UTC</td>\n",
              "      <td>2509954</td>\n",
              "      <td>Valencia</td>\n",
              "      <td>298.15</td>\n",
              "      <td>298.15</td>\n",
              "      <td>298.15</td>\n",
              "      <td>1009</td>\n",
              "      <td>65</td>\n",
              "      <td>4</td>\n",
              "      <td>250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20</td>\n",
              "      <td>801</td>\n",
              "      <td>clouds</td>\n",
              "      <td>few clouds</td>\n",
              "      <td>02n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Unnamed: 0  ... weather_icon\n",
              "dt                               ...             \n",
              "2013-10-01 02:00:00           0  ...          02n\n",
              "2013-10-01 03:00:00           1  ...          02n\n",
              "\n",
              "[2 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BtKrP3E8cKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather_group = weather[['temp']].groupby(weather.index).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cl7w5uh9Le6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e751bd78-1a14-4274-feec-4261e894de6f"
      },
      "source": [
        "weather_group.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51714, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IrxOrp7BJUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather_transformed = transform_to_windows(weather_group, load_type='temp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N069ZWM5EXTV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f17326e-a1c6-494d-8d4f-ec2893eabf2b"
      },
      "source": [
        "data.index.min(), data.index.max()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Timestamp('2016-01-05 00:00:00'), Timestamp('2018-12-31 00:00:00'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FlgdvrqFVNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzWd1s1nFYKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08cf1a97-8824-48c2-80c4-9629abddba00"
      },
      "source": [
        "weather_features.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1092, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdbZd8N6B4Yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### extract only hour 0 and work with a single hourly slice\n",
        "X_h0, Y_h0 = np.array(data[['t-1 h_0', 't-2 h_0', 't-3 h_0']]), np.array(data['t-0 h_0'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIqctl7rEweg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather_features = weather_features['2016-01-05':'2018-12-31']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N23B1gf9BTzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shifts_list = [1, 2, 3, 4]\n",
        "\n",
        "#weather_features = make_shifted_features(weather_transformed, shifts_list)\n",
        "\n",
        "### extract only hour 0 and work with a single hourly slice\n",
        "X_w_h0 = np.array(weather_features[['t-1 h_0', 't-2 h_0', 't-3 h_0']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr1L1mEKCDvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "811bc103-04bd-4d50-e981-7d6ebc6d4a4e"
      },
      "source": [
        "X_h0.shape, X_w_h0.shape"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1092, 3), (1092, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_0Xbxa3CDqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e_samples, w_samples = list(), list()\n",
        "\n",
        "for row in X_h0:\n",
        "  E = np.reshape(row, (3,1))\n",
        "  e_samples.append(E)\n",
        "\n",
        "for r in X_w_h0:\n",
        "  W = np.reshape(r, (3,1))\n",
        "  w_samples.append(W)\n",
        "\n",
        "X_e_w_h0 = np.concatenate([e_samples, w_samples], axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_03BsywCDpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32503d54-7fd4-4bb2-8e69-d8216e811d59"
      },
      "source": [
        "X_e_w_h0.shape"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1092, 3, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBUybIGBCDmA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c65d504-706c-44f7-bc1d-8d9031026dcf"
      },
      "source": [
        "X_e_w_h0 = X_e_w_h0.reshape(X_e_w_h0.shape[0], 6)\n",
        "X_e_w_h0[0]"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([26751.    ,   286.17  , 27227.    ,   281.7487, 24937.    ,\n",
              "         286.298 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GhgHNI1LFq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "197b521c-62f6-4a1f-a761-874c69effce7"
      },
      "source": [
        "X_h0[0]"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([26751., 27227., 24937.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N65K5OrWCDkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f961b96d-23b8-43a1-c9eb-d62cdf675c44"
      },
      "source": [
        "X_w_h0[0]"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([286.17  , 281.7487, 286.298 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UsUXrnyCDhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into test and train\n",
        "split = int(X_e_w_h0.shape[0] * 0.8)\n",
        "X_train_ew_h0, X_test_ew_h0 = X_e_w_h0[:split, :], X_e_w_h0[split:, :]\n",
        "Y_train_h0, Y_test_h0 = Y_h0[:split], Y_h0[split:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCs8d3qod-41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test_h0 = Y_h0[split:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPIUr1FSCDfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler_x, scaler_y= MinMaxScaler(), MinMaxScaler()\n",
        "scaler_x.fit(X_train_ew_h0)\n",
        "scaler_y.fit(np.reshape(Y_train_h0, (-1,1)))\n",
        "\n",
        "X_train_ew_h0_f = scaler_x.transform(X_train_ew_h0)\n",
        "Y_train_h0_f = scaler_y.transform(np.reshape(Y_train_h0, (-1,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg2TgUP7CDcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABnoqXcmPgxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_multi = Sequential()\n",
        "model_multi.add(Dense(100, activation='relu', input_dim = 6))\n",
        "model_multi.add(Dense(1))\n",
        "\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch : 1e-8 * 10**(epoch/20))\n",
        "\n",
        "optimizer = optimizer=tf.keras.optimizers.Adam(learning_rate=5e-3)\n",
        "\n",
        "model_multi.compile(optimizer=optimizer, loss='mae')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_AjSzDbPgtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_multi = model_multi.fit(X_train_ew_h0_f, Y_train_h0_f, epochs=100, batch_size=32)#, callbacks=[lr_schedule])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIa5-dHTPgpz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "7415b5dd-7b25-4f0d-fb29-fe47f348d423"
      },
      "source": [
        "plot_loss(history_multi)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAGjCAYAAAAB5k3nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSw2YDcnPgnG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c18a6aec-e5f0-4032-c770-79eea6b3c79c"
      },
      "source": [
        "Y_hat_ew_h0_f = model_multi.predict(X_test_ew_h0)\n",
        "\n",
        "Y_hat_ew_h0_f[:5]"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13288.068],\n",
              "       [10583.93 ],\n",
              "       [10685.57 ],\n",
              "       [14716.923],\n",
              "       [14561.657]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK-wU6K8ckeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af00a409-ce70-4691-f764-8c0e42d6872d"
      },
      "source": [
        "Y_hat_ew_h0_f[:].shape, Y_test_h0.shape"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((219, 1), (219,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arwqshjee7OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opwy4FaxfxDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58d70ac6-f3d2-4671-b069-b1c41b2ca38c"
      },
      "source": [
        "mean_absolute_error(Y_test_h0, Y_hat_ew_h0_f)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12422.344316317067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CJtUUwqfxAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKI5IFdUfw35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L364Fpg7fww8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKo-JeEEfwtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmzf2NtiCGAn",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TxwRgDY-joe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_to_windows(data, load_type='actual_load'):\n",
        "    \"\"\"\n",
        "    Input\n",
        "    \n",
        "    Output\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    #from the original datetime index create new columns with each of the year, month, day, and hour.\n",
        "    data.loc[:,'year'] = data.index.year\n",
        "    data.loc[:,'month'] = data.index.month\n",
        "    data.loc[:,'day'] = data.index.day\n",
        "    data.loc[:,'hours'] = data.index.hour\n",
        "    \n",
        "    #construct datetimes from the split year, month, day columns\n",
        "    data.loc[:,'date'] = pd.to_datetime(data.loc[:,['year', 'month', 'day']], format='%Y-%m-%d', errors='ignore')\n",
        "    \n",
        "    #set the index to dates only\n",
        "    data = data.set_index(pd.DatetimeIndex(data['date']))\n",
        "    \n",
        "    #drop non target columns \n",
        "    data = data.loc[:,[load_type, 'hours']]\n",
        "    \n",
        "    #pivot the table into the format Date h0, h1, ...h23\n",
        "    data = data.pivot(columns='hours', values=load_type)\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpfBvuP-BG4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shift_by_days(data, num_days):\n",
        "    \"\"\"\n",
        "    Input a timeseries of the form 24 hourly measurements per day\n",
        "    \n",
        "    Output returns \n",
        "    \n",
        "    \"\"\"\n",
        "    data_shifted = data.shift(num_days)\n",
        "    \n",
        "    return data_shifted\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4zMfn14BbvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_shifted_features(data, shifts_list):\n",
        "    \n",
        "    #set the columns names on the original data set\n",
        "    data = rename_cols(data, 0)\n",
        "    \n",
        "    #initate list of dataframes\n",
        "    periods = [data]\n",
        "    \n",
        "    #cycle through list of shifts i.e. features\n",
        "    for shift in shifts_list:\n",
        "        \n",
        "        #shift the data by shift value\n",
        "        data_shifted = shift_by_days(data, shift)\n",
        "\n",
        "        #update column identifers\n",
        "        data_shifted = rename_cols(data_shifted, shift)\n",
        "    \n",
        "        periods.append(data_shifted)\n",
        "        \n",
        "    #concatenate all shifted datasets into one dataframe.    \n",
        "    data = pd.concat(periods, axis = 1)\n",
        "    \n",
        "    data = trim_length(data, shifts_list)\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H8KjkGNBd-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rename_cols(data, shift):\n",
        "    \n",
        "    cols = data.columns\n",
        "    \n",
        "    cols_list = []\n",
        "    \n",
        "    for idx, col in enumerate(cols):\n",
        "        \n",
        "        new_col = 't-' + str(shift) + ' h_' + str(idx)\n",
        "        \n",
        "        cols_list.append(new_col)\n",
        "        \n",
        "    data.columns = cols_list\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-tu5FajBg3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trim_length(data, shifts_list):\n",
        "    \n",
        "    start_point = sorted(shifts_list, reverse=True)[0]\n",
        "    \n",
        "    return data.iloc[start_point:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcn6DDxrBi8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}